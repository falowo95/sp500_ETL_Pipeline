[2023-03-28T17:30:58.126+0000] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:30:58.131+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:30:58.132+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:30:58.132+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:31:01.353+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:31:01.341+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:31:01.368+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:31:01.538+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 3.415 seconds
[2023-03-28T17:31:32.472+0000] {processor.py:153} INFO - Started process (PID=76) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:31:32.477+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:31:32.481+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:31:32.481+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:31:33.171+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:31:33.169+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:31:33.174+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:31:33.193+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.751 seconds
[2023-03-28T17:32:03.518+0000] {processor.py:153} INFO - Started process (PID=119) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:32:03.522+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:32:03.524+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:32:03.524+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:32:04.171+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:32:04.169+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:32:04.174+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:32:04.193+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.681 seconds
[2023-03-28T17:32:34.595+0000] {processor.py:153} INFO - Started process (PID=149) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:32:34.598+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:32:34.599+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:32:34.599+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:32:35.206+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:32:35.203+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:32:35.208+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:32:35.226+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.638 seconds
[2023-03-28T17:33:05.588+0000] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:33:05.590+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:33:05.592+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:33:05.592+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:33:06.234+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:33:06.232+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:33:06.238+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:33:06.257+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.674 seconds
[2023-03-28T17:33:36.493+0000] {processor.py:153} INFO - Started process (PID=232) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:33:36.496+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:33:36.498+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:33:36.497+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:33:37.171+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:33:37.169+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:33:37.173+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:33:37.190+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.701 seconds
[2023-03-28T17:34:07.629+0000] {processor.py:153} INFO - Started process (PID=263) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:34:07.633+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:34:07.635+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:34:07.635+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:34:08.367+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:34:08.365+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:34:08.372+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:34:08.395+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.770 seconds
[2023-03-28T17:34:38.764+0000] {processor.py:153} INFO - Started process (PID=306) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:34:38.766+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:34:38.768+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:34:38.768+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:34:39.379+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:34:39.376+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:34:39.381+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:34:39.401+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.641 seconds
[2023-03-28T17:35:09.760+0000] {processor.py:153} INFO - Started process (PID=349) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:35:09.763+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:35:09.765+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:35:09.765+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:35:10.375+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:35:10.373+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:35:10.378+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:35:10.394+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.641 seconds
[2023-03-28T17:35:40.459+0000] {processor.py:153} INFO - Started process (PID=381) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:35:40.462+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:35:40.463+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:35:40.463+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:35:41.024+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:35:41.022+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:35:41.028+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:35:41.045+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.591 seconds
[2023-03-28T17:36:11.418+0000] {processor.py:153} INFO - Started process (PID=424) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:36:11.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:36:11.423+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:36:11.423+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:36:12.108+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:36:12.106+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:36:12.111+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:36:12.128+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.716 seconds
[2023-03-28T17:36:42.482+0000] {processor.py:153} INFO - Started process (PID=467) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:36:42.485+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:36:42.486+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:36:42.486+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:36:43.086+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:36:43.084+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:36:43.088+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:36:43.104+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.626 seconds
[2023-03-28T17:37:13.403+0000] {processor.py:153} INFO - Started process (PID=509) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:37:13.404+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:37:13.405+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:37:13.405+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:37:13.899+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:37:13.896+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:37:13.903+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:37:13.946+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.546 seconds
[2023-03-28T17:37:44.306+0000] {processor.py:153} INFO - Started process (PID=541) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:37:44.308+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:37:44.310+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:37:44.310+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:37:44.742+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:37:44.740+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:37:44.748+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:37:44.769+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.467 seconds
[2023-03-28T17:38:14.994+0000] {processor.py:153} INFO - Started process (PID=583) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:38:14.996+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:38:14.997+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:38:14.997+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:38:15.412+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:38:15.410+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:38:15.415+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:38:15.430+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.438 seconds
[2023-03-28T17:38:45.675+0000] {processor.py:153} INFO - Started process (PID=628) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:38:45.677+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:38:45.679+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:38:45.679+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:38:46.168+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:38:46.166+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:38:46.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:38:46.188+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.517 seconds
[2023-03-28T17:39:16.546+0000] {processor.py:153} INFO - Started process (PID=660) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:39:16.549+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:39:16.551+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:39:16.550+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:39:16.966+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:39:16.964+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:39:16.968+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:39:16.982+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.439 seconds
[2023-03-28T17:39:47.202+0000] {processor.py:153} INFO - Started process (PID=703) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:39:47.205+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:39:47.207+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:39:47.206+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:39:47.637+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:39:47.635+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:39:47.641+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:39:47.656+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.459 seconds
[2023-03-28T17:40:18.027+0000] {processor.py:153} INFO - Started process (PID=748) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:40:18.029+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:40:18.031+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:40:18.031+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:40:18.467+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:40:18.465+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:40:18.471+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:40:18.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.466 seconds
[2023-03-28T17:40:48.766+0000] {processor.py:153} INFO - Started process (PID=780) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:40:48.768+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:40:48.770+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:40:48.770+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:40:49.199+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:40:49.197+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:40:49.204+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:40:49.219+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.456 seconds
[2023-03-28T17:41:19.622+0000] {processor.py:153} INFO - Started process (PID=824) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:41:19.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:41:19.626+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:41:19.626+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:41:20.200+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:41:20.198+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:41:20.203+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:41:20.219+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.601 seconds
[2023-03-28T17:41:50.365+0000] {processor.py:153} INFO - Started process (PID=867) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:41:50.369+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:41:50.371+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:41:50.371+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:41:50.798+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:41:50.796+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:41:50.802+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:41:50.820+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.460 seconds
[2023-03-28T17:42:21.068+0000] {processor.py:153} INFO - Started process (PID=898) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:42:21.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:42:21.071+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:42:21.071+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:42:21.553+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:42:21.551+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:42:21.556+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:42:21.572+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.507 seconds
[2023-03-28T17:42:51.880+0000] {processor.py:153} INFO - Started process (PID=940) to work on /opt/airflow/dags/first_dag.py
[2023-03-28T17:42:51.882+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28T17:42:51.884+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:42:51.884+0000] {dagbag.py:532} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28T17:42:52.318+0000] {logging_mixin.py:137} INFO - [2023-03-28T17:42:52.315+0000] {dagbag.py:341} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 337, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 108, in launch_gateway
    raise RuntimeError("Java gateway process exited before sending its port number")
RuntimeError: Java gateway process exited before sending its port number
[2023-03-28T17:42:52.325+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28T17:42:52.341+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/first_dag.py took 0.467 seconds
[2023-03-28 17:58:59,709] {processor.py:163} INFO - Started process (PID=344) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 17:58:59,770] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 17:58:59,807] {logging_mixin.py:109} INFO - [2023-03-28 17:58:59,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 17:59:29,963] {logging_mixin.py:109} INFO - [2023-03-28 17:59:29,942] {timeout.py:36} ERROR - Process timed out, PID: 344
[2023-03-28 17:59:30,088] {logging_mixin.py:109} INFO - [2023-03-28 17:59:29,990] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/__init__.py", line 20, in <module>
    from pandas.core.arrays.string_arrow import ArrowStringArray
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 344
[2023-03-28 17:59:30,384] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 17:59:30,727] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.045 seconds
[2023-03-28 18:00:01,747] {processor.py:163} INFO - Started process (PID=397) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:00:01,776] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:00:01,791] {logging_mixin.py:109} INFO - [2023-03-28 18:00:01,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:00:32,280] {logging_mixin.py:109} INFO - [2023-03-28 18:00:32,235] {timeout.py:36} ERROR - Process timed out, PID: 397
[2023-03-28 18:00:32,452] {logging_mixin.py:109} INFO - [2023-03-28 18:00:32,289] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 73, in <module>
    from pandas.core.frame import DataFrame
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 193, in <module>
    from pandas.core.series import Series
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 397
[2023-03-28 18:00:32,892] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:00:33,065] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.398 seconds
[2023-03-28 18:01:04,133] {processor.py:163} INFO - Started process (PID=451) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:01:04,141] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:01:04,155] {logging_mixin.py:109} INFO - [2023-03-28 18:01:04,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:09:26,426] {processor.py:163} INFO - Started process (PID=250) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:09:26,445] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:09:26,458] {logging_mixin.py:109} INFO - [2023-03-28 18:09:26,457] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:09:56,827] {logging_mixin.py:109} INFO - [2023-03-28 18:09:56,824] {timeout.py:36} ERROR - Process timed out, PID: 250
[2023-03-28 18:09:56,879] {logging_mixin.py:109} INFO - [2023-03-28 18:09:56,839] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 11, in <module>
    import pyspark
  File "/opt/spark/python/pyspark/__init__.py", line 53, in <module>
    from pyspark.rdd import RDD, RDDBarrier
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 250
[2023-03-28 18:09:57,083] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:09:57,227] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.827 seconds
[2023-03-28 18:10:11,160] {processor.py:163} INFO - Started process (PID=298) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:10:11,183] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:10:11,212] {logging_mixin.py:109} INFO - [2023-03-28 18:10:11,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:10:41,363] {logging_mixin.py:109} INFO - [2023-03-28 18:10:41,294] {timeout.py:36} ERROR - Process timed out, PID: 298
[2023-03-28 18:10:41,474] {logging_mixin.py:109} INFO - [2023-03-28 18:10:41,405] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 298
[2023-03-28 18:10:41,986] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:10:42,262] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.164 seconds
[2023-03-28 18:11:13,903] {processor.py:163} INFO - Started process (PID=405) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:11:13,923] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:11:13,957] {logging_mixin.py:109} INFO - [2023-03-28 18:11:13,957] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:11:44,256] {logging_mixin.py:109} INFO - [2023-03-28 18:11:44,172] {timeout.py:36} ERROR - Process timed out, PID: 405
[2023-03-28 18:11:44,479] {logging_mixin.py:109} INFO - [2023-03-28 18:11:44,320] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 11, in <module>
    import pyspark
  File "/opt/spark/python/pyspark/__init__.py", line 53, in <module>
    from pyspark.rdd import RDD, RDDBarrier
  File "/opt/spark/python/pyspark/rdd.py", line 34, in <module>
    from pyspark.java_gateway import local_connect_and_auth
  File "/opt/spark/python/pyspark/java_gateway.py", line 32, in <module>
    from pyspark.serializers import read_int, write_with_length, UTF8Deserializer
  File "/opt/spark/python/pyspark/serializers.py", line 67, in <module>
    from pyspark import cloudpickle
  File "/opt/spark/python/pyspark/cloudpickle/__init__.py", line 4, in <module>
    from pyspark.cloudpickle.cloudpickle import *  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 405
[2023-03-28 18:11:45,431] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:11:46,257] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 32.466 seconds
[2023-03-28 18:24:21,354] {processor.py:163} INFO - Started process (PID=251) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:24:21,364] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:24:21,374] {logging_mixin.py:109} INFO - [2023-03-28 18:24:21,373] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:24:51,412] {logging_mixin.py:109} INFO - [2023-03-28 18:24:51,405] {timeout.py:36} ERROR - Process timed out, PID: 251
[2023-03-28 18:24:51,421] {logging_mixin.py:109} INFO - [2023-03-28 18:24:51,417] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 251
[2023-03-28 18:24:51,493] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:24:51,553] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.247 seconds
[2023-03-28 18:25:22,152] {processor.py:163} INFO - Started process (PID=370) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:25:22,162] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:25:22,172] {logging_mixin.py:109} INFO - [2023-03-28 18:25:22,172] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:25:52,195] {logging_mixin.py:109} INFO - [2023-03-28 18:25:52,189] {timeout.py:36} ERROR - Process timed out, PID: 370
[2023-03-28 18:25:52,206] {logging_mixin.py:109} INFO - [2023-03-28 18:25:52,199] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 370
[2023-03-28 18:25:52,210] {logging_mixin.py:109} INFO - [2023-03-28 18:25:52,209] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:25:52,218] {logging_mixin.py:109} INFO - [2023-03-28 18:25:52,212] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 370

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:25:52,223] {logging_mixin.py:109} INFO - [2023-03-28 18:25:52,221] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:25:52,280] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:25:52,313] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.189 seconds
[2023-03-28 18:26:22,703] {processor.py:163} INFO - Started process (PID=490) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:26:22,714] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:26:22,723] {logging_mixin.py:109} INFO - [2023-03-28 18:26:22,722] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:26:52,759] {logging_mixin.py:109} INFO - [2023-03-28 18:26:52,745] {timeout.py:36} ERROR - Process timed out, PID: 490
[2023-03-28 18:26:52,780] {logging_mixin.py:109} INFO - [2023-03-28 18:26:52,767] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 490
[2023-03-28 18:26:52,784] {logging_mixin.py:109} INFO - [2023-03-28 18:26:52,783] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:26:52,796] {logging_mixin.py:109} INFO - [2023-03-28 18:26:52,787] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 490

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:26:52,804] {logging_mixin.py:109} INFO - [2023-03-28 18:26:52,800] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:26:52,876] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:26:52,912] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.217 seconds
[2023-03-28 18:27:23,262] {processor.py:163} INFO - Started process (PID=658) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:27:23,268] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:27:23,273] {logging_mixin.py:109} INFO - [2023-03-28 18:27:23,272] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:27:53,340] {logging_mixin.py:109} INFO - [2023-03-28 18:27:53,334] {timeout.py:36} ERROR - Process timed out, PID: 658
[2023-03-28 18:27:53,351] {logging_mixin.py:109} INFO - [2023-03-28 18:27:53,343] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 658
[2023-03-28 18:27:53,353] {logging_mixin.py:109} INFO - [2023-03-28 18:27:53,353] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:27:53,362] {logging_mixin.py:109} INFO - [2023-03-28 18:27:53,355] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 658

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:27:53,368] {logging_mixin.py:109} INFO - [2023-03-28 18:27:53,365] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:27:53,422] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:27:53,456] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.168 seconds
[2023-03-28 18:28:24,111] {processor.py:163} INFO - Started process (PID=821) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:28:24,117] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:28:24,120] {logging_mixin.py:109} INFO - [2023-03-28 18:28:24,120] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:28:54,157] {logging_mixin.py:109} INFO - [2023-03-28 18:28:54,145] {timeout.py:36} ERROR - Process timed out, PID: 821
[2023-03-28 18:28:54,196] {logging_mixin.py:109} INFO - [2023-03-28 18:28:54,165] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 821
[2023-03-28 18:28:54,202] {logging_mixin.py:109} INFO - [2023-03-28 18:28:54,202] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:28:54,237] {logging_mixin.py:109} INFO - [2023-03-28 18:28:54,217] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 821

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:28:54,248] {logging_mixin.py:109} INFO - [2023-03-28 18:28:54,241] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:28:54,415] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:28:54,488] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.386 seconds
[2023-03-28 18:29:25,407] {processor.py:163} INFO - Started process (PID=989) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:29:25,415] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:29:25,420] {logging_mixin.py:109} INFO - [2023-03-28 18:29:25,420] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:29:55,504] {logging_mixin.py:109} INFO - [2023-03-28 18:29:55,472] {timeout.py:36} ERROR - Process timed out, PID: 989
[2023-03-28 18:29:55,539] {logging_mixin.py:109} INFO - [2023-03-28 18:29:55,511] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 989
[2023-03-28 18:29:55,550] {logging_mixin.py:109} INFO - [2023-03-28 18:29:55,548] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:29:55,587] {logging_mixin.py:109} INFO - [2023-03-28 18:29:55,555] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 989

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:29:55,597] {logging_mixin.py:109} INFO - [2023-03-28 18:29:55,593] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:29:55,703] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:29:55,784] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.396 seconds
[2023-03-28 18:30:26,317] {processor.py:163} INFO - Started process (PID=1157) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:30:26,322] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:30:26,326] {logging_mixin.py:109} INFO - [2023-03-28 18:30:26,325] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:30:56,413] {logging_mixin.py:109} INFO - [2023-03-28 18:30:56,390] {timeout.py:36} ERROR - Process timed out, PID: 1157
[2023-03-28 18:30:56,443] {logging_mixin.py:109} INFO - [2023-03-28 18:30:56,422] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1157
[2023-03-28 18:30:56,448] {logging_mixin.py:109} INFO - [2023-03-28 18:30:56,447] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:30:56,465] {logging_mixin.py:109} INFO - [2023-03-28 18:30:56,451] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1157

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:30:56,506] {logging_mixin.py:109} INFO - [2023-03-28 18:30:56,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:30:56,743] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:30:56,859] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.549 seconds
[2023-03-28 18:31:28,222] {processor.py:163} INFO - Started process (PID=1322) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:31:28,228] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:31:28,231] {logging_mixin.py:109} INFO - [2023-03-28 18:31:28,231] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:31:58,259] {logging_mixin.py:109} INFO - [2023-03-28 18:31:58,248] {timeout.py:36} ERROR - Process timed out, PID: 1322
[2023-03-28 18:31:58,283] {logging_mixin.py:109} INFO - [2023-03-28 18:31:58,265] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1322
[2023-03-28 18:31:58,294] {logging_mixin.py:109} INFO - [2023-03-28 18:31:58,294] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:31:58,319] {logging_mixin.py:109} INFO - [2023-03-28 18:31:58,300] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1322

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:31:58,345] {logging_mixin.py:109} INFO - [2023-03-28 18:31:58,330] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:31:58,513] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:31:58,584] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.369 seconds
[2023-03-28 18:32:29,294] {processor.py:163} INFO - Started process (PID=1483) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:32:29,300] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:32:29,303] {logging_mixin.py:109} INFO - [2023-03-28 18:32:29,302] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:32:59,346] {logging_mixin.py:109} INFO - [2023-03-28 18:32:59,318] {timeout.py:36} ERROR - Process timed out, PID: 1483
[2023-03-28 18:32:59,403] {logging_mixin.py:109} INFO - [2023-03-28 18:32:59,376] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1483
[2023-03-28 18:32:59,618] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:32:59,701] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.417 seconds
[2023-03-28 18:33:02,891] {processor.py:163} INFO - Started process (PID=1575) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:33:02,898] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:33:02,912] {logging_mixin.py:109} INFO - [2023-03-28 18:33:02,911] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:33:32,965] {logging_mixin.py:109} INFO - [2023-03-28 18:33:32,947] {timeout.py:36} ERROR - Process timed out, PID: 1575
[2023-03-28 18:33:32,982] {logging_mixin.py:109} INFO - [2023-03-28 18:33:32,971] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1575
[2023-03-28 18:33:32,986] {logging_mixin.py:109} INFO - [2023-03-28 18:33:32,985] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:33:33,005] {logging_mixin.py:109} INFO - [2023-03-28 18:33:32,990] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1575

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:33:33,018] {logging_mixin.py:109} INFO - [2023-03-28 18:33:33,014] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:33:33,145] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:33:33,227] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.355 seconds
[2023-03-28 18:42:29,305] {processor.py:163} INFO - Started process (PID=235) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:42:29,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:42:29,323] {logging_mixin.py:109} INFO - [2023-03-28 18:42:29,322] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:42:59,357] {logging_mixin.py:109} INFO - [2023-03-28 18:42:59,353] {timeout.py:36} ERROR - Process timed out, PID: 235
[2023-03-28 18:42:59,399] {logging_mixin.py:109} INFO - [2023-03-28 18:42:59,372] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 235
[2023-03-28 18:42:59,599] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:42:59,749] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.475 seconds
[2023-03-28 18:43:30,084] {processor.py:163} INFO - Started process (PID=353) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:43:30,096] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:43:30,103] {logging_mixin.py:109} INFO - [2023-03-28 18:43:30,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:44:00,173] {logging_mixin.py:109} INFO - [2023-03-28 18:44:00,128] {timeout.py:36} ERROR - Process timed out, PID: 353
[2023-03-28 18:44:00,280] {logging_mixin.py:109} INFO - [2023-03-28 18:44:00,231] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 353
[2023-03-28 18:44:00,657] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:44:00,872] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.807 seconds
[2023-03-28 18:44:32,446] {processor.py:163} INFO - Started process (PID=477) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:44:32,451] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:44:32,454] {logging_mixin.py:109} INFO - [2023-03-28 18:44:32,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:45:02,496] {logging_mixin.py:109} INFO - [2023-03-28 18:45:02,476] {timeout.py:36} ERROR - Process timed out, PID: 477
[2023-03-28 18:45:02,533] {logging_mixin.py:109} INFO - [2023-03-28 18:45:02,510] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 477
[2023-03-28 18:45:02,541] {logging_mixin.py:109} INFO - [2023-03-28 18:45:02,540] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:45:02,566] {logging_mixin.py:109} INFO - [2023-03-28 18:45:02,544] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 477

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:45:02,580] {logging_mixin.py:109} INFO - [2023-03-28 18:45:02,574] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:45:02,725] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:45:02,829] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.348 seconds
[2023-03-28 18:45:33,735] {processor.py:163} INFO - Started process (PID=641) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:45:33,741] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:45:33,745] {logging_mixin.py:109} INFO - [2023-03-28 18:45:33,744] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:46:03,828] {logging_mixin.py:109} INFO - [2023-03-28 18:46:03,803] {timeout.py:36} ERROR - Process timed out, PID: 641
[2023-03-28 18:46:03,858] {logging_mixin.py:109} INFO - [2023-03-28 18:46:03,835] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 641
[2023-03-28 18:46:03,875] {logging_mixin.py:109} INFO - [2023-03-28 18:46:03,874] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:46:03,929] {logging_mixin.py:109} INFO - [2023-03-28 18:46:03,878] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 641

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:46:03,954] {logging_mixin.py:109} INFO - [2023-03-28 18:46:03,935] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:46:04,167] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:46:04,210] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.483 seconds
[2023-03-28 18:46:34,642] {processor.py:163} INFO - Started process (PID=778) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:46:34,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:46:34,652] {logging_mixin.py:109} INFO - [2023-03-28 18:46:34,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:47:04,712] {logging_mixin.py:109} INFO - [2023-03-28 18:47:04,694] {timeout.py:36} ERROR - Process timed out, PID: 778
[2023-03-28 18:47:04,748] {logging_mixin.py:109} INFO - [2023-03-28 18:47:04,724] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 778
[2023-03-28 18:47:04,756] {logging_mixin.py:109} INFO - [2023-03-28 18:47:04,755] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:47:04,846] {logging_mixin.py:109} INFO - [2023-03-28 18:47:04,811] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 778

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:47:04,902] {logging_mixin.py:109} INFO - [2023-03-28 18:47:04,858] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 23, in <module>
  File "/opt/airflow/dags/stock_data_transform.py", line 24, in <module>
    )
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:47:05,019] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:47:05,110] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.476 seconds
[2023-03-28 18:47:35,761] {processor.py:163} INFO - Started process (PID=945) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:47:35,767] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:47:35,772] {logging_mixin.py:109} INFO - [2023-03-28 18:47:35,771] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:48:05,801] {logging_mixin.py:109} INFO - [2023-03-28 18:48:05,795] {timeout.py:36} ERROR - Process timed out, PID: 945
[2023-03-28 18:48:05,834] {logging_mixin.py:109} INFO - [2023-03-28 18:48:05,812] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 945
[2023-03-28 18:48:05,840] {logging_mixin.py:109} INFO - [2023-03-28 18:48:05,839] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:48:05,856] {logging_mixin.py:109} INFO - [2023-03-28 18:48:05,844] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 945

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:48:05,892] {logging_mixin.py:109} INFO - [2023-03-28 18:48:05,872] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 22, in <module>
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:48:06,008] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:48:06,076] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.324 seconds
[2023-03-28 18:48:36,823] {processor.py:163} INFO - Started process (PID=1100) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:48:36,834] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:48:36,839] {logging_mixin.py:109} INFO - [2023-03-28 18:48:36,838] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:49:06,868] {logging_mixin.py:109} INFO - [2023-03-28 18:49:06,862] {timeout.py:36} ERROR - Process timed out, PID: 1100
[2023-03-28 18:49:06,919] {logging_mixin.py:109} INFO - [2023-03-28 18:49:06,893] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1100
[2023-03-28 18:49:06,949] {logging_mixin.py:109} INFO - [2023-03-28 18:49:06,948] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:49:07,019] {logging_mixin.py:109} INFO - [2023-03-28 18:49:06,953] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1100

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:49:07,036] {logging_mixin.py:109} INFO - [2023-03-28 18:49:07,027] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:49:07,277] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:49:07,430] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.617 seconds
[2023-03-28 18:49:38,185] {processor.py:163} INFO - Started process (PID=1260) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:49:38,191] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:49:38,195] {logging_mixin.py:109} INFO - [2023-03-28 18:49:38,195] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:50:08,211] {logging_mixin.py:109} INFO - [2023-03-28 18:50:08,206] {timeout.py:36} ERROR - Process timed out, PID: 1260
[2023-03-28 18:50:08,270] {logging_mixin.py:109} INFO - [2023-03-28 18:50:08,215] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1260
[2023-03-28 18:50:08,274] {logging_mixin.py:109} INFO - [2023-03-28 18:50:08,273] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:50:08,298] {logging_mixin.py:109} INFO - [2023-03-28 18:50:08,277] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1260

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:50:08,315] {logging_mixin.py:109} INFO - [2023-03-28 18:50:08,310] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:50:08,414] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:50:08,481] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.306 seconds
[2023-03-28 18:50:39,060] {processor.py:163} INFO - Started process (PID=1415) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:50:39,068] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:50:39,090] {logging_mixin.py:109} INFO - [2023-03-28 18:50:39,090] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 18:51:09,110] {logging_mixin.py:109} INFO - [2023-03-28 18:51:09,104] {timeout.py:36} ERROR - Process timed out, PID: 1415
[2023-03-28 18:51:09,122] {logging_mixin.py:109} INFO - [2023-03-28 18:51:09,114] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1415
[2023-03-28 18:51:09,125] {logging_mixin.py:109} INFO - [2023-03-28 18:51:09,124] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 18:51:09,133] {logging_mixin.py:109} INFO - [2023-03-28 18:51:09,127] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1415

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 18:51:09,139] {logging_mixin.py:109} INFO - [2023-03-28 18:51:09,136] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 18:51:09,265] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 18:51:09,368] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.319 seconds
[2023-03-28 18:51:39,802] {processor.py:163} INFO - Started process (PID=1578) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 18:51:39,814] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 18:51:39,833] {logging_mixin.py:109} INFO - [2023-03-28 18:51:39,832] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 20:56:22,139] {processor.py:163} INFO - Started process (PID=263) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 20:56:22,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 20:56:22,169] {logging_mixin.py:109} INFO - [2023-03-28 20:56:22,168] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 20:56:52,194] {logging_mixin.py:109} INFO - [2023-03-28 20:56:52,191] {timeout.py:36} ERROR - Process timed out, PID: 263
[2023-03-28 20:56:52,255] {logging_mixin.py:109} INFO - [2023-03-28 20:56:52,214] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 143, in <module>
    from pandas.io.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/api.py", line 8, in <module>
    from pandas.io.excel import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/excel/__init__.py", line 10, in <module>
    from pandas.io.excel._xlwt import XlwtWriter as _XlwtWriter
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 963, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 906, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1280, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1252, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1371, in find_spec
  File "<frozen importlib._bootstrap_external>", line 40, in _relax_case
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 263
[2023-03-28 20:56:52,481] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 20:56:52,552] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.438 seconds
[2023-03-28 20:57:23,177] {processor.py:163} INFO - Started process (PID=316) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 20:57:23,193] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 20:57:23,203] {logging_mixin.py:109} INFO - [2023-03-28 20:57:23,202] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 20:57:53,310] {logging_mixin.py:109} INFO - [2023-03-28 20:57:53,241] {timeout.py:36} ERROR - Process timed out, PID: 316
[2023-03-28 20:57:53,388] {logging_mixin.py:109} INFO - [2023-03-28 20:57:53,346] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 316
[2023-03-28 20:57:53,736] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 20:57:53,911] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.754 seconds
[2023-03-28 20:58:25,209] {processor.py:163} INFO - Started process (PID=429) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 20:58:25,228] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 20:58:25,241] {logging_mixin.py:109} INFO - [2023-03-28 20:58:25,238] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 20:58:55,276] {logging_mixin.py:109} INFO - [2023-03-28 20:58:55,264] {timeout.py:36} ERROR - Process timed out, PID: 429
[2023-03-28 20:58:55,355] {logging_mixin.py:109} INFO - [2023-03-28 20:58:55,320] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 429
[2023-03-28 20:58:55,620] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 20:58:55,705] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.544 seconds
[2023-03-28 20:59:27,097] {processor.py:163} INFO - Started process (PID=558) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 20:59:27,119] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 20:59:27,128] {logging_mixin.py:109} INFO - [2023-03-28 20:59:27,128] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 20:59:57,182] {logging_mixin.py:109} INFO - [2023-03-28 20:59:57,149] {timeout.py:36} ERROR - Process timed out, PID: 558
[2023-03-28 20:59:57,231] {logging_mixin.py:109} INFO - [2023-03-28 20:59:57,187] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 558
[2023-03-28 20:59:57,236] {logging_mixin.py:109} INFO - [2023-03-28 20:59:57,234] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 20:59:57,254] {logging_mixin.py:109} INFO - [2023-03-28 20:59:57,239] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 558

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 20:59:57,268] {logging_mixin.py:109} INFO - [2023-03-28 20:59:57,261] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 20:59:57,393] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 20:59:57,554] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.495 seconds
[2023-03-28 21:00:28,066] {processor.py:163} INFO - Started process (PID=704) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:00:28,072] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:00:28,079] {logging_mixin.py:109} INFO - [2023-03-28 21:00:28,079] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:00:58,133] {logging_mixin.py:109} INFO - [2023-03-28 21:00:58,093] {timeout.py:36} ERROR - Process timed out, PID: 704
[2023-03-28 21:00:58,198] {logging_mixin.py:109} INFO - [2023-03-28 21:00:58,147] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 704
[2023-03-28 21:00:58,220] {logging_mixin.py:109} INFO - [2023-03-28 21:00:58,215] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 21:00:58,271] {logging_mixin.py:109} INFO - [2023-03-28 21:00:58,229] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 704

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 21:00:58,304] {logging_mixin.py:109} INFO - [2023-03-28 21:00:58,300] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 21:00:58,454] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:00:58,541] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.485 seconds
[2023-03-28 21:01:29,007] {processor.py:163} INFO - Started process (PID=869) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:01:29,013] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:01:29,017] {logging_mixin.py:109} INFO - [2023-03-28 21:01:29,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:01:59,143] {logging_mixin.py:109} INFO - [2023-03-28 21:01:59,075] {timeout.py:36} ERROR - Process timed out, PID: 869
[2023-03-28 21:01:59,224] {logging_mixin.py:109} INFO - [2023-03-28 21:01:59,176] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 869
[2023-03-28 21:01:59,238] {logging_mixin.py:109} INFO - [2023-03-28 21:01:59,237] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 21:01:59,260] {logging_mixin.py:109} INFO - [2023-03-28 21:01:59,244] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 869

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 21:01:59,273] {logging_mixin.py:109} INFO - [2023-03-28 21:01:59,269] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 21:01:59,397] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:01:59,438] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.442 seconds
[2023-03-28 21:02:30,046] {processor.py:163} INFO - Started process (PID=1031) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:02:30,052] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:02:30,056] {logging_mixin.py:109} INFO - [2023-03-28 21:02:30,055] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:03:00,085] {logging_mixin.py:109} INFO - [2023-03-28 21:03:00,080] {timeout.py:36} ERROR - Process timed out, PID: 1031
[2023-03-28 21:03:00,101] {logging_mixin.py:109} INFO - [2023-03-28 21:03:00,092] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1031
[2023-03-28 21:03:00,115] {logging_mixin.py:109} INFO - [2023-03-28 21:03:00,114] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 21:03:00,126] {logging_mixin.py:109} INFO - [2023-03-28 21:03:00,120] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1031

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 21:03:00,136] {logging_mixin.py:109} INFO - [2023-03-28 21:03:00,131] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 21:03:00,298] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:03:00,411] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.372 seconds
[2023-03-28 21:03:30,841] {processor.py:163} INFO - Started process (PID=1199) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:03:30,849] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:03:30,857] {logging_mixin.py:109} INFO - [2023-03-28 21:03:30,856] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:04:00,886] {logging_mixin.py:109} INFO - [2023-03-28 21:04:00,875] {timeout.py:36} ERROR - Process timed out, PID: 1199
[2023-03-28 21:04:00,931] {logging_mixin.py:109} INFO - [2023-03-28 21:04:00,890] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1199
[2023-03-28 21:04:00,939] {logging_mixin.py:109} INFO - [2023-03-28 21:04:00,938] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 21:04:00,955] {logging_mixin.py:109} INFO - [2023-03-28 21:04:00,944] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1199

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 21:04:00,972] {logging_mixin.py:109} INFO - [2023-03-28 21:04:00,966] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 21:04:01,133] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:04:01,239] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.414 seconds
[2023-03-28 21:04:31,700] {processor.py:163} INFO - Started process (PID=1364) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:04:31,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:04:31,712] {logging_mixin.py:109} INFO - [2023-03-28 21:04:31,712] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:05:01,740] {logging_mixin.py:109} INFO - [2023-03-28 21:05:01,731] {timeout.py:36} ERROR - Process timed out, PID: 1364
[2023-03-28 21:05:01,754] {logging_mixin.py:109} INFO - [2023-03-28 21:05:01,749] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1364
[2023-03-28 21:05:01,824] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:05:01,853] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.172 seconds
[2023-03-28 21:05:32,213] {processor.py:163} INFO - Started process (PID=1468) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:05:32,222] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:05:32,228] {logging_mixin.py:109} INFO - [2023-03-28 21:05:32,227] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:06:02,248] {logging_mixin.py:109} INFO - [2023-03-28 21:06:02,243] {timeout.py:36} ERROR - Process timed out, PID: 1468
[2023-03-28 21:06:02,260] {logging_mixin.py:109} INFO - [2023-03-28 21:06:02,252] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1468
[2023-03-28 21:06:02,263] {logging_mixin.py:109} INFO - [2023-03-28 21:06:02,263] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 21:06:02,273] {logging_mixin.py:109} INFO - [2023-03-28 21:06:02,266] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1468

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 21:06:02,280] {logging_mixin.py:109} INFO - [2023-03-28 21:06:02,277] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 21:06:02,335] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:06:02,383] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.189 seconds
[2023-03-28 21:06:32,855] {processor.py:163} INFO - Started process (PID=1594) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:06:32,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:06:32,869] {logging_mixin.py:109} INFO - [2023-03-28 21:06:32,869] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:07:02,888] {logging_mixin.py:109} INFO - [2023-03-28 21:07:02,883] {timeout.py:36} ERROR - Process timed out, PID: 1594
[2023-03-28 21:07:02,909] {logging_mixin.py:109} INFO - [2023-03-28 21:07:02,892] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1594
[2023-03-28 21:07:02,913] {logging_mixin.py:109} INFO - [2023-03-28 21:07:02,913] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 21:07:02,922] {logging_mixin.py:109} INFO - [2023-03-28 21:07:02,916] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1594

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 21:07:02,928] {logging_mixin.py:109} INFO - [2023-03-28 21:07:02,926] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 21:07:03,029] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:07:03,088] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.251 seconds
[2023-03-28 21:07:33,673] {processor.py:163} INFO - Started process (PID=1723) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:07:33,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:07:33,689] {logging_mixin.py:109} INFO - [2023-03-28 21:07:33,688] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:08:03,718] {logging_mixin.py:109} INFO - [2023-03-28 21:08:03,707] {timeout.py:36} ERROR - Process timed out, PID: 1723
[2023-03-28 21:08:03,734] {logging_mixin.py:109} INFO - [2023-03-28 21:08:03,728] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1723
[2023-03-28 21:08:03,789] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:08:03,816] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.163 seconds
[2023-03-28 21:08:34,117] {processor.py:163} INFO - Started process (PID=1802) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:08:34,126] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:08:34,133] {logging_mixin.py:109} INFO - [2023-03-28 21:08:34,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:09:04,158] {logging_mixin.py:109} INFO - [2023-03-28 21:09:04,149] {timeout.py:36} ERROR - Process timed out, PID: 1802
[2023-03-28 21:09:04,186] {logging_mixin.py:109} INFO - [2023-03-28 21:09:04,172] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1802
[2023-03-28 21:09:04,250] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:09:04,294] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.193 seconds
[2023-03-28 21:09:34,791] {processor.py:163} INFO - Started process (PID=1919) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:09:34,800] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:09:34,807] {logging_mixin.py:109} INFO - [2023-03-28 21:09:34,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:10:04,830] {logging_mixin.py:109} INFO - [2023-03-28 21:10:04,823] {timeout.py:36} ERROR - Process timed out, PID: 1919
[2023-03-28 21:10:04,868] {logging_mixin.py:109} INFO - [2023-03-28 21:10:04,849] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1919
[2023-03-28 21:10:04,932] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:10:04,967] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.195 seconds
[2023-03-28 21:10:35,485] {processor.py:163} INFO - Started process (PID=2034) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:10:35,495] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:10:35,501] {logging_mixin.py:109} INFO - [2023-03-28 21:10:35,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:11:05,550] {logging_mixin.py:109} INFO - [2023-03-28 21:11:05,526] {timeout.py:36} ERROR - Process timed out, PID: 2034
[2023-03-28 21:11:05,595] {logging_mixin.py:109} INFO - [2023-03-28 21:11:05,573] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2034
[2023-03-28 21:11:05,792] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:11:05,828] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.362 seconds
[2023-03-28 21:11:36,360] {processor.py:163} INFO - Started process (PID=2148) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:11:36,369] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:11:36,373] {logging_mixin.py:109} INFO - [2023-03-28 21:11:36,373] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:12:06,450] {logging_mixin.py:109} INFO - [2023-03-28 21:12:06,392] {timeout.py:36} ERROR - Process timed out, PID: 2148
[2023-03-28 21:12:06,485] {logging_mixin.py:109} INFO - [2023-03-28 21:12:06,466] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2148
[2023-03-28 21:12:06,607] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:12:06,742] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.400 seconds
[2023-03-28 21:12:37,712] {processor.py:163} INFO - Started process (PID=2255) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:12:37,727] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:12:37,743] {logging_mixin.py:109} INFO - [2023-03-28 21:12:37,742] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:13:07,818] {logging_mixin.py:109} INFO - [2023-03-28 21:13:07,787] {timeout.py:36} ERROR - Process timed out, PID: 2255
[2023-03-28 21:13:07,862] {logging_mixin.py:109} INFO - [2023-03-28 21:13:07,845] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2255
[2023-03-28 21:13:08,129] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:13:08,337] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.648 seconds
[2023-03-28 21:13:39,140] {processor.py:163} INFO - Started process (PID=2362) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:13:39,150] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:13:39,156] {logging_mixin.py:109} INFO - [2023-03-28 21:13:39,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:14:09,281] {logging_mixin.py:109} INFO - [2023-03-28 21:14:09,193] {timeout.py:36} ERROR - Process timed out, PID: 2362
[2023-03-28 21:14:09,459] {logging_mixin.py:109} INFO - [2023-03-28 21:14:09,372] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2362
[2023-03-28 21:14:09,981] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:14:10,188] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.076 seconds
[2023-03-28 21:14:41,059] {processor.py:163} INFO - Started process (PID=2470) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:14:41,072] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:14:41,084] {logging_mixin.py:109} INFO - [2023-03-28 21:14:41,082] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:15:11,229] {logging_mixin.py:109} INFO - [2023-03-28 21:15:11,142] {timeout.py:36} ERROR - Process timed out, PID: 2470
[2023-03-28 21:15:11,703] {logging_mixin.py:109} INFO - [2023-03-28 21:15:11,563] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2470
[2023-03-28 21:15:26,565] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:15:26,895] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 45.865 seconds
[2023-03-28 21:15:58,520] {processor.py:163} INFO - Started process (PID=2592) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:15:58,537] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:15:58,549] {logging_mixin.py:109} INFO - [2023-03-28 21:15:58,549] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:16:28,673] {logging_mixin.py:109} INFO - [2023-03-28 21:16:28,613] {timeout.py:36} ERROR - Process timed out, PID: 2592
[2023-03-28 21:16:28,796] {logging_mixin.py:109} INFO - [2023-03-28 21:16:28,741] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2592
[2023-03-28 21:16:29,160] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:16:29,494] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.036 seconds
[2023-03-28 21:17:01,294] {processor.py:163} INFO - Started process (PID=2693) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:17:01,312] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:17:01,327] {logging_mixin.py:109} INFO - [2023-03-28 21:17:01,327] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:17:32,671] {logging_mixin.py:109} INFO - [2023-03-28 21:17:31,640] {timeout.py:36} ERROR - Process timed out, PID: 2693
[2023-03-28 21:17:33,352] {logging_mixin.py:109} INFO - [2023-03-28 21:17:33,133] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2693
[2023-03-28 21:17:34,891] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:17:35,136] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 33.870 seconds
[2023-03-28 21:18:07,285] {processor.py:163} INFO - Started process (PID=2801) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:18:07,302] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:18:07,307] {logging_mixin.py:109} INFO - [2023-03-28 21:18:07,306] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:18:37,441] {logging_mixin.py:109} INFO - [2023-03-28 21:18:37,362] {timeout.py:36} ERROR - Process timed out, PID: 2801
[2023-03-28 21:18:38,028] {logging_mixin.py:109} INFO - [2023-03-28 21:18:37,855] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2801
[2023-03-28 21:18:45,551] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:18:45,800] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 38.518 seconds
[2023-03-28 21:19:17,721] {processor.py:163} INFO - Started process (PID=2926) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:19:17,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:19:17,796] {logging_mixin.py:109} INFO - [2023-03-28 21:19:17,795] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:19:49,562] {logging_mixin.py:109} INFO - [2023-03-28 21:19:48,933] {timeout.py:36} ERROR - Process timed out, PID: 2926
[2023-03-28 21:19:50,956] {logging_mixin.py:109} INFO - [2023-03-28 21:19:50,778] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2926
[2023-03-28 21:19:51,431] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:19:51,924] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 34.281 seconds
[2023-03-28 21:20:23,380] {processor.py:163} INFO - Started process (PID=3035) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:20:23,400] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:20:23,418] {logging_mixin.py:109} INFO - [2023-03-28 21:20:23,413] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:20:53,577] {logging_mixin.py:109} INFO - [2023-03-28 21:20:53,463] {timeout.py:36} ERROR - Process timed out, PID: 3035
[2023-03-28 21:20:53,772] {logging_mixin.py:109} INFO - [2023-03-28 21:20:53,647] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3035
[2023-03-28 21:20:54,803] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:20:55,116] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.791 seconds
[2023-03-28 21:21:27,040] {processor.py:163} INFO - Started process (PID=3147) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:21:27,050] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:21:27,057] {logging_mixin.py:109} INFO - [2023-03-28 21:21:27,055] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:21:57,214] {logging_mixin.py:109} INFO - [2023-03-28 21:21:57,091] {timeout.py:36} ERROR - Process timed out, PID: 3147
[2023-03-28 21:21:57,477] {logging_mixin.py:109} INFO - [2023-03-28 21:21:57,338] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3147
[2023-03-28 21:21:58,012] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:21:58,264] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.245 seconds
[2023-03-28 21:22:29,554] {processor.py:163} INFO - Started process (PID=3264) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:22:29,569] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:22:29,584] {logging_mixin.py:109} INFO - [2023-03-28 21:22:29,583] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:22:59,725] {logging_mixin.py:109} INFO - [2023-03-28 21:22:59,639] {timeout.py:36} ERROR - Process timed out, PID: 3264
[2023-03-28 21:22:59,799] {logging_mixin.py:109} INFO - [2023-03-28 21:22:59,747] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3264
[2023-03-28 21:23:00,603] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:23:00,983] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.469 seconds
[2023-03-28 21:23:33,008] {processor.py:163} INFO - Started process (PID=3370) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:23:33,023] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:23:33,063] {logging_mixin.py:109} INFO - [2023-03-28 21:23:33,062] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:24:03,178] {logging_mixin.py:109} INFO - [2023-03-28 21:24:03,122] {timeout.py:36} ERROR - Process timed out, PID: 3370
[2023-03-28 21:24:03,266] {logging_mixin.py:109} INFO - [2023-03-28 21:24:03,202] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3370
[2023-03-28 21:24:03,725] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:24:03,836] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.941 seconds
[2023-03-28 21:24:37,791] {processor.py:163} INFO - Started process (PID=3468) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:24:37,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:24:37,813] {logging_mixin.py:109} INFO - [2023-03-28 21:24:37,808] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:25:07,875] {logging_mixin.py:109} INFO - [2023-03-28 21:25:07,856] {timeout.py:36} ERROR - Process timed out, PID: 3468
[2023-03-28 21:25:07,937] {logging_mixin.py:109} INFO - [2023-03-28 21:25:07,908] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3468
[2023-03-28 21:25:08,348] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:25:08,526] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.801 seconds
[2023-03-28 21:25:39,655] {processor.py:163} INFO - Started process (PID=3570) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:25:39,671] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:25:39,684] {logging_mixin.py:109} INFO - [2023-03-28 21:25:39,682] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:26:09,853] {logging_mixin.py:109} INFO - [2023-03-28 21:26:09,733] {timeout.py:36} ERROR - Process timed out, PID: 3570
[2023-03-28 21:26:10,025] {logging_mixin.py:109} INFO - [2023-03-28 21:26:09,934] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3570
[2023-03-28 21:26:16,707] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:26:17,109] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 37.491 seconds
[2023-03-28 21:26:50,366] {processor.py:163} INFO - Started process (PID=3689) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:26:50,495] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:26:50,552] {logging_mixin.py:109} INFO - [2023-03-28 21:26:50,538] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:27:20,836] {logging_mixin.py:109} INFO - [2023-03-28 21:27:20,692] {timeout.py:36} ERROR - Process timed out, PID: 3689
[2023-03-28 21:27:21,103] {logging_mixin.py:109} INFO - [2023-03-28 21:27:21,020] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3689
[2023-03-28 21:27:21,499] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:27:21,707] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.444 seconds
[2023-03-28 21:27:54,912] {processor.py:163} INFO - Started process (PID=3786) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:27:55,018] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:27:55,059] {logging_mixin.py:109} INFO - [2023-03-28 21:27:55,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:28:25,417] {logging_mixin.py:109} INFO - [2023-03-28 21:28:25,363] {timeout.py:36} ERROR - Process timed out, PID: 3786
[2023-03-28 21:28:25,596] {logging_mixin.py:109} INFO - [2023-03-28 21:28:25,456] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 24, in <module>
    from pandas.core.algorithms import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3786
[2023-03-28 21:28:26,355] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:28:26,867] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 32.170 seconds
[2023-03-28 21:28:58,507] {processor.py:163} INFO - Started process (PID=3856) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:28:58,532] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:28:58,606] {logging_mixin.py:109} INFO - [2023-03-28 21:28:58,568] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:29:28,677] {logging_mixin.py:109} INFO - [2023-03-28 21:29:28,673] {timeout.py:36} ERROR - Process timed out, PID: 3856
[2023-03-28 21:29:28,718] {logging_mixin.py:109} INFO - [2023-03-28 21:29:28,683] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3856
[2023-03-28 21:29:29,140] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:29:29,503] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.110 seconds
[2023-03-28 21:30:00,786] {processor.py:163} INFO - Started process (PID=3962) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:30:00,795] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:30:00,803] {logging_mixin.py:109} INFO - [2023-03-28 21:30:00,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:30:30,891] {logging_mixin.py:109} INFO - [2023-03-28 21:30:30,859] {timeout.py:36} ERROR - Process timed out, PID: 3962
[2023-03-28 21:30:31,021] {logging_mixin.py:109} INFO - [2023-03-28 21:30:30,964] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp5btvh869/tmpjbsho8ng'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 3962
[2023-03-28 21:30:37,756] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:30:38,288] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 37.528 seconds
[2023-03-28 21:31:11,336] {processor.py:163} INFO - Started process (PID=4079) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:31:11,371] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:31:11,394] {logging_mixin.py:109} INFO - [2023-03-28 21:31:11,390] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:31:41,547] {logging_mixin.py:109} INFO - [2023-03-28 21:31:41,461] {timeout.py:36} ERROR - Process timed out, PID: 4079
[2023-03-28 21:31:41,662] {logging_mixin.py:109} INFO - [2023-03-28 21:31:41,589] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4079
[2023-03-28 21:31:41,980] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:31:42,168] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.916 seconds
[2023-03-28 21:32:14,437] {processor.py:163} INFO - Started process (PID=4175) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:32:14,704] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:32:14,724] {logging_mixin.py:109} INFO - [2023-03-28 21:32:14,724] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:32:45,126] {logging_mixin.py:109} INFO - [2023-03-28 21:32:44,912] {timeout.py:36} ERROR - Process timed out, PID: 4175
[2023-03-28 21:32:45,821] {logging_mixin.py:109} INFO - [2023-03-28 21:32:45,280] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py", line 7, in <module>
    from pandas.util.version import Version
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/__init__.py", line 1, in <module>
    from pandas.util._decorators import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 14, in <module>
    from pandas._libs.properties import cache_readonly  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 13, in <module>
    from pandas._libs.interval import Interval
  File "pandas/_libs/interval.pyx", line 1, in init pandas._libs.interval
  File "pandas/_libs/hashtable.pyx", line 1, in init pandas._libs.hashtable
  File "pandas/_libs/missing.pyx", line 1, in init pandas._libs.missing
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 31, in <module>
    from pandas._libs.tslibs.conversion import (
  File "pandas/_libs/tslibs/conversion.pyx", line 63, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/parsing.pyx", line 1, in init pandas._libs.tslibs.parsing
  File "pandas/_libs/tslibs/offsets.pyx", line 1, in init pandas._libs.tslibs.offsets
  File "pandas/_libs/tslibs/timedeltas.pyx", line 61, in init pandas._libs.tslibs.timedeltas
  File "pandas/_libs/tslibs/fields.pyx", line 49, in init pandas._libs.tslibs.fields
  File "pandas/_libs/tslibs/strptime.pyx", line 633, in init pandas._libs.tslibs.strptime
  File "pandas/_libs/tslibs/strptime.pyx", line 538, in pandas._libs.tslibs.strptime.TimeRE.__init__
  File "pandas/_libs/tslibs/strptime.pyx", line 415, in pandas._libs.tslibs.strptime.LocaleTime.__init__
  File "pandas/_libs/tslibs/strptime.pyx", line 442, in pandas._libs.tslibs.strptime.LocaleTime.__calc_month
  File "/usr/local/lib/python3.7/calendar.py", line 58, in __getitem__
    def __getitem__(self, i):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4175
[2023-03-28 21:32:50,097] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:32:50,920] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 36.632 seconds
[2023-03-28 21:33:22,518] {processor.py:163} INFO - Started process (PID=4251) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:33:22,545] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:33:22,561] {logging_mixin.py:109} INFO - [2023-03-28 21:33:22,560] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:33:52,617] {logging_mixin.py:109} INFO - [2023-03-28 21:33:52,601] {timeout.py:36} ERROR - Process timed out, PID: 4251
[2023-03-28 21:33:52,700] {logging_mixin.py:109} INFO - [2023-03-28 21:33:52,649] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4251
[2023-03-28 21:33:53,126] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:33:53,417] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.995 seconds
[2023-03-28 21:34:25,085] {processor.py:163} INFO - Started process (PID=4358) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:34:25,111] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:34:25,131] {logging_mixin.py:109} INFO - [2023-03-28 21:34:25,130] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:34:55,272] {logging_mixin.py:109} INFO - [2023-03-28 21:34:55,224] {timeout.py:36} ERROR - Process timed out, PID: 4358
[2023-03-28 21:34:55,422] {logging_mixin.py:109} INFO - [2023-03-28 21:34:55,306] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 119, in <module>
    from pandas.tseries.api import infer_freq
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 963, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 906, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1280, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1252, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1395, in find_spec
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4358
[2023-03-28 21:34:55,928] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:34:56,205] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.201 seconds
[2023-03-28 21:35:28,198] {processor.py:163} INFO - Started process (PID=4424) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:35:28,232] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:35:28,241] {logging_mixin.py:109} INFO - [2023-03-28 21:35:28,239] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:35:58,367] {logging_mixin.py:109} INFO - [2023-03-28 21:35:58,283] {timeout.py:36} ERROR - Process timed out, PID: 4424
[2023-03-28 21:35:58,477] {logging_mixin.py:109} INFO - [2023-03-28 21:35:58,423] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4424
[2023-03-28 21:35:59,015] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:35:59,196] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.055 seconds
[2023-03-28 21:36:30,336] {processor.py:163} INFO - Started process (PID=4537) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:36:30,363] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:36:30,386] {logging_mixin.py:109} INFO - [2023-03-28 21:36:30,376] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:37:00,464] {logging_mixin.py:109} INFO - [2023-03-28 21:37:00,440] {timeout.py:36} ERROR - Process timed out, PID: 4537
[2023-03-28 21:37:00,530] {logging_mixin.py:109} INFO - [2023-03-28 21:37:00,512] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4537
[2023-03-28 21:37:00,957] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:37:01,062] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.757 seconds
[2023-03-28 21:37:33,094] {processor.py:163} INFO - Started process (PID=4645) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:37:33,127] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:37:33,175] {logging_mixin.py:109} INFO - [2023-03-28 21:37:33,152] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:38:04,430] {logging_mixin.py:109} INFO - [2023-03-28 21:38:04,427] {timeout.py:36} ERROR - Process timed out, PID: 4645
[2023-03-28 21:38:04,462] {logging_mixin.py:109} WARNING - Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x40067d80e0>
[2023-03-28 21:38:04,472] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 21:38:04,508] {logging_mixin.py:109} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 109, in remove
[2023-03-28 21:38:04,562] {logging_mixin.py:109} WARNING -     def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):
[2023-03-28 21:38:04,567] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 21:38:04,578] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 21:38:04,583] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4645
[2023-03-28 21:38:28,152] {processor.py:163} INFO - Started process (PID=4728) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:38:28,168] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:38:28,182] {logging_mixin.py:109} INFO - [2023-03-28 21:38:28,178] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:38:58,218] {logging_mixin.py:109} INFO - [2023-03-28 21:38:58,208] {timeout.py:36} ERROR - Process timed out, PID: 4728
[2023-03-28 21:38:58,246] {logging_mixin.py:109} INFO - [2023-03-28 21:38:58,231] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4728
[2023-03-28 21:38:58,449] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:38:58,623] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.494 seconds
[2023-03-28 21:39:30,768] {processor.py:163} INFO - Started process (PID=4856) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:39:30,833] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:39:30,872] {logging_mixin.py:109} INFO - [2023-03-28 21:39:30,871] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:40:01,013] {logging_mixin.py:109} INFO - [2023-03-28 21:40:00,974] {timeout.py:36} ERROR - Process timed out, PID: 4856
[2023-03-28 21:40:01,285] {logging_mixin.py:109} INFO - [2023-03-28 21:40:01,034] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 76, in <module>
    from pandas.core.groupby.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/groupby.py", line 43, in <module>
    import pandas._libs.groupby as libgroupby
  File "pandas/_libs/groupby.pyx", line 50, in init pandas._libs.groupby
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/core/getlimits.py", line 514, in __init__
    def __init__(self, int_type):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4856
[2023-03-28 21:40:01,988] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:40:02,360] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.699 seconds
[2023-03-28 21:40:33,468] {processor.py:163} INFO - Started process (PID=4932) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:40:33,506] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:40:33,529] {logging_mixin.py:109} INFO - [2023-03-28 21:40:33,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:41:03,598] {logging_mixin.py:109} INFO - [2023-03-28 21:41:03,589] {timeout.py:36} ERROR - Process timed out, PID: 4932
[2023-03-28 21:41:03,710] {logging_mixin.py:109} INFO - [2023-03-28 21:41:03,618] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 4932
[2023-03-28 21:41:04,079] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:41:04,259] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.887 seconds
[2023-03-28 21:41:35,293] {processor.py:163} INFO - Started process (PID=5042) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:41:35,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:41:35,334] {logging_mixin.py:109} INFO - [2023-03-28 21:41:35,330] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:42:05,399] {logging_mixin.py:109} INFO - [2023-03-28 21:42:05,372] {timeout.py:36} ERROR - Process timed out, PID: 5042
[2023-03-28 21:42:05,451] {logging_mixin.py:109} INFO - [2023-03-28 21:42:05,417] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5042
[2023-03-28 21:42:05,843] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:42:06,002] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.785 seconds
[2023-03-28 21:42:39,009] {processor.py:163} INFO - Started process (PID=5144) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:42:39,199] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:42:39,280] {logging_mixin.py:109} INFO - [2023-03-28 21:42:39,259] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:43:09,793] {logging_mixin.py:109} INFO - [2023-03-28 21:43:09,781] {timeout.py:36} ERROR - Process timed out, PID: 5144
[2023-03-28 21:43:09,934] {logging_mixin.py:109} INFO - [2023-03-28 21:43:09,814] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5144
[2023-03-28 21:43:10,440] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:43:10,873] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 32.235 seconds
[2023-03-28 21:43:44,733] {processor.py:163} INFO - Started process (PID=5252) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:43:44,805] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:43:44,995] {logging_mixin.py:109} INFO - [2023-03-28 21:43:44,937] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:44:15,494] {logging_mixin.py:109} INFO - [2023-03-28 21:44:15,467] {timeout.py:36} ERROR - Process timed out, PID: 5252
[2023-03-28 21:44:15,560] {logging_mixin.py:109} INFO - [2023-03-28 21:44:15,535] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5252
[2023-03-28 21:44:16,255] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:44:17,054] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 32.872 seconds
[2023-03-28 21:44:48,441] {processor.py:163} INFO - Started process (PID=5362) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:44:48,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:44:48,477] {logging_mixin.py:109} INFO - [2023-03-28 21:44:48,473] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:45:18,633] {logging_mixin.py:109} INFO - [2023-03-28 21:45:18,629] {timeout.py:36} ERROR - Process timed out, PID: 5362
[2023-03-28 21:45:18,671] {logging_mixin.py:109} INFO - [2023-03-28 21:45:18,641] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 23, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/pyarrow.py", line 6, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/__init__.py", line 63, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 416, in parent
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5362
[2023-03-28 21:45:18,925] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:45:19,223] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.838 seconds
[2023-03-28 21:45:50,307] {processor.py:163} INFO - Started process (PID=5421) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:45:50,334] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:45:50,360] {logging_mixin.py:109} INFO - [2023-03-28 21:45:50,355] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:46:20,560] {logging_mixin.py:109} INFO - [2023-03-28 21:46:20,472] {timeout.py:36} ERROR - Process timed out, PID: 5421
[2023-03-28 21:46:20,784] {logging_mixin.py:109} INFO - [2023-03-28 21:46:20,601] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py", line 7, in <module>
    from pandas.util.version import Version
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/__init__.py", line 7, in <module>
    from pandas.core.util.hashing import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/util/hashing.py", line 24, in <module>
    from pandas.core.dtypes.common import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/dtypes/common.py", line 26, in <module>
    from pandas.core.dtypes.base import _registry as registry
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/dtypes/base.py", line 22, in <module>
    from pandas.core.dtypes.generic import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5421
[2023-03-28 21:46:21,422] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:46:21,739] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.512 seconds
[2023-03-28 21:46:53,428] {processor.py:163} INFO - Started process (PID=5480) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:46:53,461] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:46:53,482] {logging_mixin.py:109} INFO - [2023-03-28 21:46:53,471] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:47:23,606] {logging_mixin.py:109} INFO - [2023-03-28 21:47:23,555] {timeout.py:36} ERROR - Process timed out, PID: 5480
[2023-03-28 21:47:23,839] {logging_mixin.py:109} INFO - [2023-03-28 21:47:23,628] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py", line 7, in <module>
    from pandas.util.version import Version
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/__init__.py", line 1, in <module>
    from pandas.util._decorators import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 14, in <module>
    from pandas._libs.properties import cache_readonly  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 13, in <module>
    from pandas._libs.interval import Interval
  File "pandas/_libs/intervaltree.pxi", line 7, in init pandas._libs.interval
  File "pandas/_libs/algos.pyx", line 60, in init pandas._libs.algos
  File "<frozen importlib._bootstrap>", line 1009, in _handle_fromlist
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5480
[2023-03-28 21:47:24,156] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:47:24,480] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.111 seconds
[2023-03-28 21:47:55,992] {processor.py:163} INFO - Started process (PID=5541) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:47:56,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:47:56,059] {logging_mixin.py:109} INFO - [2023-03-28 21:47:56,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:48:26,371] {logging_mixin.py:109} INFO - [2023-03-28 21:48:26,334] {timeout.py:36} ERROR - Process timed out, PID: 5541
[2023-03-28 21:48:26,415] {logging_mixin.py:109} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x4011998e60>
[2023-03-28 21:48:26,420] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 21:48:26,438] {logging_mixin.py:109} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 358, in remove
[2023-03-28 21:48:26,500] {logging_mixin.py:109} WARNING -     def remove(k, selfref=ref(self)):
[2023-03-28 21:48:26,519] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 21:48:26,529] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 21:48:26,548] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5541
[2023-03-28 21:48:52,344] {processor.py:163} INFO - Started process (PID=5613) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:48:52,374] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:48:52,389] {logging_mixin.py:109} INFO - [2023-03-28 21:48:52,388] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:49:22,518] {logging_mixin.py:109} INFO - [2023-03-28 21:49:22,474] {timeout.py:36} ERROR - Process timed out, PID: 5613
[2023-03-28 21:49:22,806] {logging_mixin.py:109} INFO - [2023-03-28 21:49:22,560] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 8, in <module>
    from pyspark.sql import SparkSession
  File "/opt/spark/python/pyspark/__init__.py", line 53, in <module>
    from pyspark.rdd import RDD, RDDBarrier
  File "/opt/spark/python/pyspark/rdd.py", line 40, in <module>
    from pyspark.statcounter import StatCounter
  File "/opt/spark/python/pyspark/statcounter.py", line 24, in <module>
    from numpy import maximum, minimum, sqrt
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/__init__.py", line 254, in <module>
    warnings.filterwarnings("ignore", message="numpy.dtype size changed")
  File "/usr/local/lib/python3.7/warnings.py", line 155, in filterwarnings
    message = re.compile(message, re.I)
  File "/usr/local/lib/python3.7/re.py", line 236, in compile
    return _compile(pattern, flags)
  File "/usr/local/lib/python3.7/re.py", line 288, in _compile
    p = sre_compile.compile(pattern, flags)
  File "/usr/local/lib/python3.7/sre_compile.py", line 776, in compile
    indexgroup = [None] * p.pattern.groups
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5613
[2023-03-28 21:49:23,493] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:49:23,919] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.923 seconds
[2023-03-28 21:49:54,717] {processor.py:163} INFO - Started process (PID=5683) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:49:54,771] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:49:54,851] {logging_mixin.py:109} INFO - [2023-03-28 21:49:54,813] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:50:25,620] {logging_mixin.py:109} INFO - [2023-03-28 21:50:25,618] {timeout.py:36} ERROR - Process timed out, PID: 5683
[2023-03-28 21:50:25,663] {logging_mixin.py:109} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x4011998e60>
[2023-03-28 21:50:25,665] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 21:50:25,679] {logging_mixin.py:109} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 358, in remove
[2023-03-28 21:50:25,730] {logging_mixin.py:109} WARNING -     def remove(k, selfref=ref(self)):
[2023-03-28 21:50:25,766] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 21:50:25,799] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 21:50:25,819] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5683
[2023-03-28 21:50:49,147] {processor.py:163} INFO - Started process (PID=5732) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:50:49,203] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:50:49,247] {logging_mixin.py:109} INFO - [2023-03-28 21:50:49,247] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:51:19,407] {logging_mixin.py:109} INFO - [2023-03-28 21:51:19,335] {timeout.py:36} ERROR - Process timed out, PID: 5732
[2023-03-28 21:51:19,698] {logging_mixin.py:109} INFO - [2023-03-28 21:51:19,449] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 24, in <module>
    from pandas.core.algorithms import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/algorithms.py", line 34, in <module>
    from pandas.core.dtypes.cast import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5732
[2023-03-28 21:51:20,843] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:51:21,697] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 32.663 seconds
[2023-03-28 21:51:55,002] {processor.py:163} INFO - Started process (PID=5798) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:51:55,046] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:51:55,061] {logging_mixin.py:109} INFO - [2023-03-28 21:51:55,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:52:25,278] {logging_mixin.py:109} INFO - [2023-03-28 21:52:25,274] {timeout.py:36} ERROR - Process timed out, PID: 5798
[2023-03-28 21:52:25,476] {logging_mixin.py:109} INFO - [2023-03-28 21:52:25,321] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 23, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/pyarrow.py", line 6, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/__init__.py", line 63, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 416, in parent
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5798
[2023-03-28 21:52:25,955] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:52:26,255] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.459 seconds
[2023-03-28 21:52:57,924] {processor.py:163} INFO - Started process (PID=5870) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:52:57,951] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:52:57,971] {logging_mixin.py:109} INFO - [2023-03-28 21:52:57,966] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:53:28,027] {logging_mixin.py:109} INFO - [2023-03-28 21:53:28,023] {timeout.py:36} ERROR - Process timed out, PID: 5870
[2023-03-28 21:53:28,071] {logging_mixin.py:109} INFO - [2023-03-28 21:53:28,045] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5870
[2023-03-28 21:53:28,574] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:53:28,858] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.072 seconds
[2023-03-28 21:54:00,612] {processor.py:163} INFO - Started process (PID=5971) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:54:00,647] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:54:00,661] {logging_mixin.py:109} INFO - [2023-03-28 21:54:00,660] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:54:30,798] {logging_mixin.py:109} INFO - [2023-03-28 21:54:30,724] {timeout.py:36} ERROR - Process timed out, PID: 5971
[2023-03-28 21:54:30,992] {logging_mixin.py:109} INFO - [2023-03-28 21:54:30,830] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 179, in <module>
    import pandas.testing
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/testing.py", line 6, in <module>
    from pandas._testing import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_testing/__init__.py", line 156, in <module>
    NULL_OBJECTS = [None, np.nan, pd.NaT, float("nan"), pd.NA, Decimal("NaN")]
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 5971
[2023-03-28 21:54:31,523] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:54:31,824] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.291 seconds
[2023-03-28 21:55:04,142] {processor.py:163} INFO - Started process (PID=6041) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:55:04,173] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:55:04,192] {logging_mixin.py:109} INFO - [2023-03-28 21:55:04,191] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:55:34,264] {logging_mixin.py:109} INFO - [2023-03-28 21:55:34,254] {timeout.py:36} ERROR - Process timed out, PID: 6041
[2023-03-28 21:55:34,314] {logging_mixin.py:109} INFO - [2023-03-28 21:55:34,291] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6041
[2023-03-28 21:55:34,669] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:55:34,846] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.779 seconds
[2023-03-28 21:56:06,194] {processor.py:163} INFO - Started process (PID=6143) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:56:06,224] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:56:06,251] {logging_mixin.py:109} INFO - [2023-03-28 21:56:06,244] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:56:36,332] {logging_mixin.py:109} INFO - [2023-03-28 21:56:36,312] {timeout.py:36} ERROR - Process timed out, PID: 6143
[2023-03-28 21:56:36,473] {logging_mixin.py:109} INFO - [2023-03-28 21:56:36,434] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6143
[2023-03-28 21:56:36,802] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:56:37,165] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.032 seconds
[2023-03-28 21:57:09,217] {processor.py:163} INFO - Started process (PID=6251) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:57:09,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:57:09,251] {logging_mixin.py:109} INFO - [2023-03-28 21:57:09,251] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:57:39,373] {logging_mixin.py:109} INFO - [2023-03-28 21:57:39,335] {timeout.py:36} ERROR - Process timed out, PID: 6251
[2023-03-28 21:57:39,590] {logging_mixin.py:109} INFO - [2023-03-28 21:57:39,389] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 73, in <module>
    from pandas.core.frame import DataFrame
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 129, in <module>
    from pandas.core import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 108, in <module>
    from pandas.core import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/indexing.py", line 14, in <module>
    from pandas._libs.indexing import NDFrameIndexerBase
  File "<frozen importlib._bootstrap>", line 416, in parent
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6251
[2023-03-28 21:57:39,972] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:57:40,292] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.142 seconds
[2023-03-28 21:58:12,008] {processor.py:163} INFO - Started process (PID=6309) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:58:12,018] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:58:12,050] {logging_mixin.py:109} INFO - [2023-03-28 21:58:12,050] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:58:42,128] {logging_mixin.py:109} INFO - [2023-03-28 21:58:42,123] {timeout.py:36} ERROR - Process timed out, PID: 6309
[2023-03-28 21:58:42,147] {logging_mixin.py:109} INFO - [2023-03-28 21:58:42,132] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6309
[2023-03-28 21:58:42,570] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:58:42,888] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.958 seconds
[2023-03-28 21:59:16,222] {processor.py:163} INFO - Started process (PID=6399) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 21:59:16,253] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 21:59:16,279] {logging_mixin.py:109} INFO - [2023-03-28 21:59:16,279] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 21:59:47,712] {logging_mixin.py:109} INFO - [2023-03-28 21:59:47,291] {timeout.py:36} ERROR - Process timed out, PID: 6399
[2023-03-28 21:59:52,610] {logging_mixin.py:109} INFO - [2023-03-28 21:59:48,555] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py", line 7, in <module>
    from pandas.util.version import Version
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/__init__.py", line 1, in <module>
    from pandas.util._decorators import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 14, in <module>
    from pandas._libs.properties import cache_readonly  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 13, in <module>
    from pandas._libs.interval import Interval
  File "pandas/_libs/interval.pyx", line 1, in init pandas._libs.interval
  File "pandas/_libs/hashtable.pyx", line 1, in init pandas._libs.hashtable
  File "pandas/_libs/missing.pyx", line 1, in init pandas._libs.missing
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 31, in <module>
    from pandas._libs.tslibs.conversion import (
  File "pandas/_libs/tslibs/conversion.pyx", line 1, in init pandas._libs.tslibs.conversion
  File "<frozen importlib._bootstrap>", line 416, in parent
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6399
[2023-03-28 21:59:53,688] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 21:59:53,870] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 37.824 seconds
[2023-03-28 22:00:26,606] {processor.py:163} INFO - Started process (PID=6474) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:00:26,643] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:00:26,698] {logging_mixin.py:109} INFO - [2023-03-28 22:00:26,691] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:00:56,868] {logging_mixin.py:109} INFO - [2023-03-28 22:00:56,769] {timeout.py:36} ERROR - Process timed out, PID: 6474
[2023-03-28 22:00:57,176] {logging_mixin.py:109} INFO - [2023-03-28 22:00:56,913] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/__init__.py", line 20, in <module>
    from pandas.core.arrays.string_arrow import ArrowStringArray
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/string_arrow.py", line 65, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 239, in <module>
    _make_global_functions()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 236, in _make_global_functions
    g[cpp_name] = g[name] = _wrap_function(name, func)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 214, in _wrap_function
    option_class)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 195, in _make_signature
    options_sig = inspect.signature(option_class)
  File "/usr/local/lib/python3.7/inspect.py", line 3083, in signature
    return Signature.from_callable(obj, follow_wrapped=follow_wrapped)
  File "/usr/local/lib/python3.7/inspect.py", line 2833, in from_callable
    follow_wrapper_chains=follow_wrapped)
  File "/usr/local/lib/python3.7/inspect.py", line 2328, in _signature_from_callable
    sigcls=sigcls)
  File "/usr/local/lib/python3.7/inspect.py", line 2284, in _signature_from_callable
    return _signature_from_function(sigcls, obj)
  File "/usr/local/lib/python3.7/inspect.py", line 2161, in _signature_from_function
    default=defaults[offset]))
  File "/usr/local/lib/python3.7/inspect.py", line 2467, in __init__
    def __init__(self, name, kind, *, default=_empty, annotation=_empty):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6474
[2023-03-28 22:00:57,795] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:00:58,373] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.938 seconds
[2023-03-28 22:01:30,885] {processor.py:163} INFO - Started process (PID=6537) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:01:30,921] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:01:30,952] {logging_mixin.py:109} INFO - [2023-03-28 22:01:30,951] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:02:01,073] {logging_mixin.py:109} INFO - [2023-03-28 22:02:01,009] {timeout.py:36} ERROR - Process timed out, PID: 6537
[2023-03-28 22:02:01,184] {logging_mixin.py:109} INFO - [2023-03-28 22:02:01,099] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 138, in __init__
    self._callsite = first_spark_call() or CallSite(None, None, None)
  File "/opt/spark/python/pyspark/traceback_utils.py", line 30, in first_spark_call
    tb = traceback.extract_stack()
  File "/usr/local/lib/python3.7/traceback.py", line 211, in extract_stack
    stack = StackSummary.extract(walk_stack(f), limit=limit)
  File "/usr/local/lib/python3.7/traceback.py", line 363, in extract
    f.line
  File "/usr/local/lib/python3.7/traceback.py", line 285, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/usr/local/lib/python3.7/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/usr/local/lib/python3.7/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6537
[2023-03-28 22:02:01,727] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:02:01,898] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.093 seconds
[2023-03-28 22:02:33,675] {processor.py:163} INFO - Started process (PID=6598) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:02:33,701] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:02:33,721] {logging_mixin.py:109} INFO - [2023-03-28 22:02:33,720] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:03:03,817] {logging_mixin.py:109} INFO - [2023-03-28 22:03:03,776] {timeout.py:36} ERROR - Process timed out, PID: 6598
[2023-03-28 22:03:03,900] {logging_mixin.py:109} INFO - [2023-03-28 22:03:03,862] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6598
[2023-03-28 22:03:04,254] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:03:04,507] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.896 seconds
[2023-03-28 22:03:36,651] {processor.py:163} INFO - Started process (PID=6699) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:03:36,694] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:03:36,718] {logging_mixin.py:109} INFO - [2023-03-28 22:03:36,712] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:04:06,805] {logging_mixin.py:109} INFO - [2023-03-28 22:04:06,775] {timeout.py:36} ERROR - Process timed out, PID: 6699
[2023-03-28 22:04:06,899] {logging_mixin.py:109} INFO - [2023-03-28 22:04:06,847] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6699
[2023-03-28 22:04:07,401] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:04:07,697] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.126 seconds
[2023-03-28 22:04:40,479] {processor.py:163} INFO - Started process (PID=6809) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:04:40,519] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:04:40,543] {logging_mixin.py:109} INFO - [2023-03-28 22:04:40,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:05:10,594] {logging_mixin.py:109} INFO - [2023-03-28 22:05:10,578] {timeout.py:36} ERROR - Process timed out, PID: 6809
[2023-03-28 22:05:10,707] {logging_mixin.py:109} INFO - [2023-03-28 22:05:10,618] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 143, in <module>
    from pandas.io.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/api.py", line 8, in <module>
    from pandas.io.excel import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 916, in get_data
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6809
[2023-03-28 22:05:11,033] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:05:11,283] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.915 seconds
[2023-03-28 22:05:43,497] {processor.py:163} INFO - Started process (PID=6880) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:05:43,531] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:05:43,545] {logging_mixin.py:109} INFO - [2023-03-28 22:05:43,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:06:13,725] {logging_mixin.py:109} INFO - [2023-03-28 22:06:13,671] {timeout.py:36} ERROR - Process timed out, PID: 6880
[2023-03-28 22:06:13,743] {logging_mixin.py:109} WARNING - Exception ignored in: <function _releaseLock at 0x40043d0830>
[2023-03-28 22:06:13,747] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 22:06:13,751] {logging_mixin.py:109} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 221, in _releaseLock
[2023-03-28 22:06:13,772] {logging_mixin.py:109} WARNING -     def _releaseLock():
[2023-03-28 22:06:13,776] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 22:06:13,786] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 22:06:13,788] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6880
[2023-03-28 22:06:39,622] {processor.py:163} INFO - Started process (PID=6970) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:06:39,635] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:06:39,645] {logging_mixin.py:109} INFO - [2023-03-28 22:06:39,642] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:07:09,696] {logging_mixin.py:109} INFO - [2023-03-28 22:07:09,678] {timeout.py:36} ERROR - Process timed out, PID: 6970
[2023-03-28 22:07:09,737] {logging_mixin.py:109} INFO - [2023-03-28 22:07:09,717] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 6970
[2023-03-28 22:07:09,920] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:07:10,013] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.431 seconds
[2023-03-28 22:07:41,542] {processor.py:163} INFO - Started process (PID=7076) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:07:41,630] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:07:41,688] {logging_mixin.py:109} INFO - [2023-03-28 22:07:41,673] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:08:12,457] {logging_mixin.py:109} INFO - [2023-03-28 22:08:12,430] {timeout.py:36} ERROR - Process timed out, PID: 7076
[2023-03-28 22:08:12,601] {logging_mixin.py:109} INFO - [2023-03-28 22:08:12,483] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/__init__.py", line 20, in <module>
    from pandas.core.arrays.string_arrow import ArrowStringArray
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/string_arrow.py", line 65, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 18, in <module>
    from pyarrow._compute import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7076
[2023-03-28 22:08:13,133] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:08:13,400] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.909 seconds
[2023-03-28 22:08:44,265] {processor.py:163} INFO - Started process (PID=7158) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:08:44,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:08:44,299] {logging_mixin.py:109} INFO - [2023-03-28 22:08:44,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:09:14,459] {logging_mixin.py:109} INFO - [2023-03-28 22:09:14,357] {timeout.py:36} ERROR - Process timed out, PID: 7158
[2023-03-28 22:09:14,545] {logging_mixin.py:109} INFO - [2023-03-28 22:09:14,494] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7158
[2023-03-28 22:09:15,352] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:09:15,665] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.436 seconds
[2023-03-28 22:09:47,303] {processor.py:163} INFO - Started process (PID=7261) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:09:47,346] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:09:47,372] {logging_mixin.py:109} INFO - [2023-03-28 22:09:47,371] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:10:17,438] {logging_mixin.py:109} INFO - [2023-03-28 22:10:17,433] {timeout.py:36} ERROR - Process timed out, PID: 7261
[2023-03-28 22:10:17,463] {logging_mixin.py:109} INFO - [2023-03-28 22:10:17,447] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpwgi4qcnd/tmp9b7u3gql'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7261
[2023-03-28 22:10:17,758] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:10:18,041] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.813 seconds
[2023-03-28 22:10:48,837] {processor.py:163} INFO - Started process (PID=7368) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:10:48,867] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:10:48,896] {logging_mixin.py:109} INFO - [2023-03-28 22:10:48,884] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:11:18,984] {logging_mixin.py:109} INFO - [2023-03-28 22:11:18,940] {timeout.py:36} ERROR - Process timed out, PID: 7368
[2023-03-28 22:11:19,053] {logging_mixin.py:109} INFO - [2023-03-28 22:11:18,989] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 23, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/pyarrow.py", line 6, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/__init__.py", line 63, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 416, in parent
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7368
[2023-03-28 22:11:19,535] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:11:19,770] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.104 seconds
[2023-03-28 22:11:51,014] {processor.py:163} INFO - Started process (PID=7429) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:11:51,045] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:11:51,059] {logging_mixin.py:109} INFO - [2023-03-28 22:11:51,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:12:21,342] {logging_mixin.py:109} INFO - [2023-03-28 22:12:21,326] {timeout.py:36} ERROR - Process timed out, PID: 7429
[2023-03-28 22:12:21,359] {logging_mixin.py:109} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x4011998e60>
[2023-03-28 22:12:21,362] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 22:12:21,365] {logging_mixin.py:109} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 358, in remove
[2023-03-28 22:12:21,381] {logging_mixin.py:109} WARNING -     def remove(k, selfref=ref(self)):
[2023-03-28 22:12:21,385] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 22:12:21,393] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 22:12:21,403] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7429
[2023-03-28 22:12:46,649] {processor.py:163} INFO - Started process (PID=7519) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:12:46,689] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:12:46,698] {logging_mixin.py:109} INFO - [2023-03-28 22:12:46,698] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:13:16,760] {logging_mixin.py:109} INFO - [2023-03-28 22:13:16,755] {timeout.py:36} ERROR - Process timed out, PID: 7519
[2023-03-28 22:13:17,235] {logging_mixin.py:109} INFO - [2023-03-28 22:13:16,809] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 73, in <module>
    from pandas.core.frame import DataFrame
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 129, in <module>
    from pandas.core import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 122, in <module>
    from pandas.core.describe import describe_ndframe
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/describe.py", line 39, in <module>
    from pandas.io.formats.format import format_percentiles
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 963, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 906, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1280, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1252, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1391, in find_spec
  File "<frozen importlib._bootstrap_external>", line 59, in _path_join
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7519
[2023-03-28 22:13:17,586] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:13:17,852] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.265 seconds
[2023-03-28 22:13:49,460] {processor.py:163} INFO - Started process (PID=7592) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:13:49,478] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:13:49,488] {logging_mixin.py:109} INFO - [2023-03-28 22:13:49,488] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:14:19,531] {logging_mixin.py:109} INFO - [2023-03-28 22:14:19,523] {timeout.py:36} ERROR - Process timed out, PID: 7592
[2023-03-28 22:14:19,542] {logging_mixin.py:109} WARNING - Exception ignored in: <module 'collections.abc' from '/usr/local/lib/python3.7/collections/abc.py'>
[2023-03-28 22:14:19,547] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 22:14:19,549] {logging_mixin.py:109} WARNING -   File "<string>", line 1, in <module>
[2023-03-28 22:14:19,557] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 22:14:19,570] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 22:14:19,574] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7592
[2023-03-28 22:14:34,551] {logging_mixin.py:109} WARNING - /usr/local/lib/python3.7/importlib/_bootstrap.py:219 RuntimeWarning: Cython module failed to patch module with custom type
[2023-03-28 22:14:43,222] {processor.py:163} INFO - Started process (PID=7677) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:14:43,245] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:14:43,258] {logging_mixin.py:109} INFO - [2023-03-28 22:14:43,257] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:15:13,375] {logging_mixin.py:109} INFO - [2023-03-28 22:15:13,354] {timeout.py:36} ERROR - Process timed out, PID: 7677
[2023-03-28 22:15:13,493] {logging_mixin.py:109} INFO - [2023-03-28 22:15:13,390] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 76, in <module>
    from pandas.core.groupby.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/groupby.py", line 43, in <module>
    import pandas._libs.groupby as libgroupby
  File "pandas/_libs/groupby.pyx", line 50, in init pandas._libs.groupby
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/core/getlimits.py", line 538, in max
    @property
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7677
[2023-03-28 22:15:13,920] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:15:14,212] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.029 seconds
[2023-03-28 22:15:45,337] {processor.py:163} INFO - Started process (PID=7762) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:15:45,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:15:45,376] {logging_mixin.py:109} INFO - [2023-03-28 22:15:45,372] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:16:15,414] {logging_mixin.py:109} INFO - [2023-03-28 22:16:15,408] {timeout.py:36} ERROR - Process timed out, PID: 7762
[2023-03-28 22:16:15,509] {logging_mixin.py:109} INFO - [2023-03-28 22:16:15,472] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7762
[2023-03-28 22:16:15,607] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:16:15,692] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.405 seconds
[2023-03-28 22:16:47,135] {processor.py:163} INFO - Started process (PID=7881) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:16:47,161] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:16:47,183] {logging_mixin.py:109} INFO - [2023-03-28 22:16:47,180] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:17:17,273] {logging_mixin.py:109} INFO - [2023-03-28 22:17:17,220] {timeout.py:36} ERROR - Process timed out, PID: 7881
[2023-03-28 22:17:17,404] {logging_mixin.py:109} INFO - [2023-03-28 22:17:17,337] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7881
[2023-03-28 22:17:17,933] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:17:18,189] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.141 seconds
[2023-03-28 22:17:49,650] {processor.py:163} INFO - Started process (PID=7998) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:17:49,667] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:17:49,686] {logging_mixin.py:109} INFO - [2023-03-28 22:17:49,682] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:18:19,754] {logging_mixin.py:109} INFO - [2023-03-28 22:18:19,740] {timeout.py:36} ERROR - Process timed out, PID: 7998
[2023-03-28 22:18:19,799] {logging_mixin.py:109} INFO - [2023-03-28 22:18:19,775] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 7998
[2023-03-28 22:18:20,153] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:18:21,020] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.303 seconds
[2023-03-28 22:18:52,563] {processor.py:163} INFO - Started process (PID=8099) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:18:52,600] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:18:52,621] {logging_mixin.py:109} INFO - [2023-03-28 22:18:52,620] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:19:22,686] {logging_mixin.py:109} INFO - [2023-03-28 22:19:22,680] {timeout.py:36} ERROR - Process timed out, PID: 8099
[2023-03-28 22:19:22,743] {logging_mixin.py:109} INFO - [2023-03-28 22:19:22,700] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8099
[2023-03-28 22:19:22,911] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:19:23,127] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.635 seconds
[2023-03-28 22:19:54,959] {processor.py:163} INFO - Started process (PID=8211) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:19:54,977] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:19:54,997] {logging_mixin.py:109} INFO - [2023-03-28 22:19:54,997] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:20:25,178] {logging_mixin.py:109} INFO - [2023-03-28 22:20:25,148] {timeout.py:36} ERROR - Process timed out, PID: 8211
[2023-03-28 22:20:25,375] {logging_mixin.py:109} INFO - [2023-03-28 22:20:25,244] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py", line 7, in <module>
    from pandas.util.version import Version
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/__init__.py", line 1, in <module>
    from pandas.util._decorators import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 14, in <module>
    from pandas._libs.properties import cache_readonly  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 13, in <module>
    from pandas._libs.interval import Interval
  File "pandas/_libs/interval.pyx", line 1, in init pandas._libs.interval
  File "pandas/_libs/hashtable.pyx", line 1, in init pandas._libs.hashtable
  File "pandas/_libs/missing.pyx", line 1, in init pandas._libs.missing
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 31, in <module>
    from pandas._libs.tslibs.conversion import (
  File "pandas/_libs/tslibs/conversion.pyx", line 1, in init pandas._libs.tslibs.conversion
  File "<frozen importlib._bootstrap>", line 416, in parent
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8211
[2023-03-28 22:20:25,942] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:20:26,257] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.449 seconds
[2023-03-28 22:20:56,982] {processor.py:163} INFO - Started process (PID=8266) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:20:57,063] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:20:57,092] {logging_mixin.py:109} INFO - [2023-03-28 22:20:57,092] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:21:27,231] {logging_mixin.py:109} INFO - [2023-03-28 22:21:27,180] {timeout.py:36} ERROR - Process timed out, PID: 8266
[2023-03-28 22:21:27,426] {logging_mixin.py:109} INFO - [2023-03-28 22:21:27,272] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/__init__.py", line 20, in <module>
    from pandas.core.arrays.string_arrow import ArrowStringArray
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/string_arrow.py", line 65, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 239, in <module>
    _make_global_functions()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 236, in _make_global_functions
    g[cpp_name] = g[name] = _wrap_function(name, func)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 214, in _wrap_function
    option_class)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 184, in _make_signature
    from inspect import Parameter
  File "<frozen importlib._bootstrap>", line 1009, in _handle_fromlist
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8266
[2023-03-28 22:21:28,006] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:21:28,426] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.613 seconds
[2023-03-28 22:22:00,184] {processor.py:163} INFO - Started process (PID=8328) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:22:00,202] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:22:00,218] {logging_mixin.py:109} INFO - [2023-03-28 22:22:00,216] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:22:30,260] {logging_mixin.py:109} INFO - [2023-03-28 22:22:30,255] {timeout.py:36} ERROR - Process timed out, PID: 8328
[2023-03-28 22:22:30,324] {logging_mixin.py:109} INFO - [2023-03-28 22:22:30,271] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8328
[2023-03-28 22:22:30,967] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:22:31,425] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.318 seconds
[2023-03-28 22:23:02,829] {processor.py:163} INFO - Started process (PID=8427) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:23:02,854] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:23:02,872] {logging_mixin.py:109} INFO - [2023-03-28 22:23:02,868] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:23:32,926] {logging_mixin.py:109} INFO - [2023-03-28 22:23:32,912] {timeout.py:36} ERROR - Process timed out, PID: 8427
[2023-03-28 22:23:33,048] {logging_mixin.py:109} INFO - [2023-03-28 22:23:32,944] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 143, in <module>
    from pandas.io.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/api.py", line 8, in <module>
    from pandas.io.excel import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/excel/__init__.py", line 1, in <module>
    from pandas.io.excel._base import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 61, in <module>
    from pandas.io.parsers import TextParser
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/__init__.py", line 1, in <module>
    from pandas.io.parsers.readers import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8427
[2023-03-28 22:23:33,351] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:23:33,713] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.939 seconds
[2023-03-28 22:24:04,948] {processor.py:163} INFO - Started process (PID=8498) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:24:04,968] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:24:04,998] {logging_mixin.py:109} INFO - [2023-03-28 22:24:04,992] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:24:35,080] {logging_mixin.py:109} INFO - [2023-03-28 22:24:35,061] {timeout.py:36} ERROR - Process timed out, PID: 8498
[2023-03-28 22:24:35,153] {logging_mixin.py:109} INFO - [2023-03-28 22:24:35,094] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 138, in __init__
    self._callsite = first_spark_call() or CallSite(None, None, None)
  File "/opt/spark/python/pyspark/traceback_utils.py", line 30, in first_spark_call
    tb = traceback.extract_stack()
  File "/usr/local/lib/python3.7/traceback.py", line 211, in extract_stack
    stack = StackSummary.extract(walk_stack(f), limit=limit)
  File "/usr/local/lib/python3.7/traceback.py", line 363, in extract
    f.line
  File "/usr/local/lib/python3.7/traceback.py", line 285, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/usr/local/lib/python3.7/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/usr/local/lib/python3.7/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/usr/local/lib/python3.7/linecache.py", line 95, in updatecache
    stat = os.stat(fullname)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8498
[2023-03-28 22:24:35,378] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:24:35,528] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.702 seconds
[2023-03-28 22:25:07,367] {processor.py:163} INFO - Started process (PID=8555) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:25:07,382] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:25:07,394] {logging_mixin.py:109} INFO - [2023-03-28 22:25:07,392] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:25:37,434] {logging_mixin.py:109} INFO - [2023-03-28 22:25:37,429] {timeout.py:36} ERROR - Process timed out, PID: 8555
[2023-03-28 22:25:37,462] {logging_mixin.py:109} INFO - [2023-03-28 22:25:37,447] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8555
[2023-03-28 22:25:37,678] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:25:37,930] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.591 seconds
[2023-03-28 22:26:12,004] {processor.py:163} INFO - Started process (PID=8652) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:26:12,110] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:26:12,178] {logging_mixin.py:109} INFO - [2023-03-28 22:26:12,165] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:26:43,910] {logging_mixin.py:109} INFO - [2023-03-28 22:26:43,834] {timeout.py:36} ERROR - Process timed out, PID: 8652
[2023-03-28 22:26:43,954] {logging_mixin.py:109} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x4011998e60>
[2023-03-28 22:26:43,971] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 22:26:44,006] {logging_mixin.py:109} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 358, in remove
[2023-03-28 22:26:44,086] {logging_mixin.py:109} WARNING -     def remove(k, selfref=ref(self)):
[2023-03-28 22:26:44,109] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 22:26:44,133] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 22:26:44,146] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8652
[2023-03-28 22:27:04,307] {processor.py:163} INFO - Started process (PID=8734) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:27:04,356] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:27:04,381] {logging_mixin.py:109} INFO - [2023-03-28 22:27:04,380] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:27:38,110] {logging_mixin.py:109} INFO - [2023-03-28 22:27:38,092] {timeout.py:36} ERROR - Process timed out, PID: 8734
[2023-03-28 22:27:38,125] {logging_mixin.py:109} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x4011998e60>
[2023-03-28 22:27:38,129] {logging_mixin.py:109} WARNING - Traceback (most recent call last):
[2023-03-28 22:27:38,138] {logging_mixin.py:109} WARNING -   File "/usr/local/lib/python3.7/weakref.py", line 358, in remove
[2023-03-28 22:27:38,171] {logging_mixin.py:109} WARNING -     def remove(k, selfref=ref(self)):
[2023-03-28 22:27:38,180] {logging_mixin.py:109} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
[2023-03-28 22:27:38,189] {logging_mixin.py:109} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-03-28 22:27:38,199] {logging_mixin.py:109} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8734
[2023-03-28 22:28:01,195] {processor.py:163} INFO - Started process (PID=8805) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:28:01,299] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:28:01,304] {logging_mixin.py:109} INFO - [2023-03-28 22:28:01,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:28:31,602] {logging_mixin.py:109} INFO - [2023-03-28 22:28:31,516] {timeout.py:36} ERROR - Process timed out, PID: 8805
[2023-03-28 22:28:32,130] {logging_mixin.py:109} INFO - [2023-03-28 22:28:31,686] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py", line 7, in <module>
    from pandas.util.version import Version
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/__init__.py", line 1, in <module>
    from pandas.util._decorators import (  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 14, in <module>
    from pandas._libs.properties import cache_readonly  # noqa
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/__init__.py", line 13, in <module>
    from pandas._libs.interval import Interval
  File "pandas/_libs/interval.pyx", line 1, in init pandas._libs.interval
  File "pandas/_libs/hashtable.pyx", line 1, in init pandas._libs.hashtable
  File "pandas/_libs/missing.pyx", line 1, in init pandas._libs.missing
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/_libs/tslibs/__init__.py", line 31, in <module>
    from pandas._libs.tslibs.conversion import (
  File "pandas/_libs/tslibs/conversion.pyx", line 63, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/parsing.pyx", line 1, in init pandas._libs.tslibs.parsing
  File "pandas/_libs/tslibs/offsets.pyx", line 1, in init pandas._libs.tslibs.offsets
  File "<frozen importlib._bootstrap>", line 194, in _lock_unlock_module
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8805
[2023-03-28 22:28:33,068] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:28:33,674] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 32.546 seconds
[2023-03-28 22:29:05,764] {processor.py:163} INFO - Started process (PID=8871) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:29:05,776] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:29:05,785] {logging_mixin.py:109} INFO - [2023-03-28 22:29:05,782] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:29:35,903] {logging_mixin.py:109} INFO - [2023-03-28 22:29:35,821] {timeout.py:36} ERROR - Process timed out, PID: 8871
[2023-03-28 22:29:36,172] {logging_mixin.py:109} INFO - [2023-03-28 22:29:35,978] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/__init__.py", line 20, in <module>
    from pandas.core.arrays.string_arrow import ArrowStringArray
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/arrays/string_arrow.py", line 65, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 239, in <module>
    _make_global_functions()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 236, in _make_global_functions
    g[cpp_name] = g[name] = _wrap_function(name, func)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 215, in _wrap_function
    return _decorate_compute_function(wrapper, name, func, option_class)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 134, in _decorate_compute_function
    wrapper.__doc__ = "".join(dedent(s) for s in doc_pieces)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/compute.py", line 134, in <genexpr>
    wrapper.__doc__ = "".join(dedent(s) for s in doc_pieces)
  File "/usr/local/lib/python3.7/textwrap.py", line 461, in dedent
    text = re.sub(r'(?m)^' + margin, '', text)
  File "/usr/local/lib/python3.7/re.py", line 194, in sub
    return _compile(pattern, flags).sub(repl, string, count)
  File "/usr/local/lib/python3.7/re.py", line 275, in _compile
    if isinstance(flags, RegexFlag):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8871
[2023-03-28 22:29:36,737] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:29:37,325] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.600 seconds
[2023-03-28 22:30:09,216] {processor.py:163} INFO - Started process (PID=8938) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:30:09,241] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:30:09,276] {logging_mixin.py:109} INFO - [2023-03-28 22:30:09,275] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:30:39,432] {logging_mixin.py:109} INFO - [2023-03-28 22:30:39,394] {timeout.py:36} ERROR - Process timed out, PID: 8938
[2023-03-28 22:30:39,564] {logging_mixin.py:109} INFO - [2023-03-28 22:30:39,473] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 143, in <module>
    from pandas.io.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/api.py", line 16, in <module>
    from pandas.io.json import read_json
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/json/__init__.py", line 1, in <module>
    from pandas.io.json._json import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 857, in get_code
  File "<frozen importlib._bootstrap_external>", line 525, in _compile_bytecode
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8938
[2023-03-28 22:30:40,309] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:30:40,632] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.477 seconds
[2023-03-28 22:31:12,847] {processor.py:163} INFO - Started process (PID=8996) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:31:12,930] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:31:12,960] {logging_mixin.py:109} INFO - [2023-03-28 22:31:12,959] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:31:43,067] {logging_mixin.py:109} INFO - [2023-03-28 22:31:43,041] {timeout.py:36} ERROR - Process timed out, PID: 8996
[2023-03-28 22:31:43,195] {logging_mixin.py:109} INFO - [2023-03-28 22:31:43,112] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 8996
[2023-03-28 22:31:43,565] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:31:43,752] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.025 seconds
[2023-03-28 22:32:15,588] {processor.py:163} INFO - Started process (PID=9100) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:32:15,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:32:15,649] {logging_mixin.py:109} INFO - [2023-03-28 22:32:15,647] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:32:45,697] {logging_mixin.py:109} INFO - [2023-03-28 22:32:45,688] {timeout.py:36} ERROR - Process timed out, PID: 9100
[2023-03-28 22:32:45,790] {logging_mixin.py:109} INFO - [2023-03-28 22:32:45,731] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 9100
[2023-03-28 22:32:46,132] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:32:46,239] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.770 seconds
[2023-03-28 22:33:18,300] {processor.py:163} INFO - Started process (PID=9211) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:33:18,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:33:18,384] {logging_mixin.py:109} INFO - [2023-03-28 22:33:18,384] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:33:48,511] {logging_mixin.py:109} INFO - [2023-03-28 22:33:48,486] {timeout.py:36} ERROR - Process timed out, PID: 9211
[2023-03-28 22:33:48,824] {logging_mixin.py:109} INFO - [2023-03-28 22:33:48,537] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 73, in <module>
    from pandas.core.frame import DataFrame
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 129, in <module>
    from pandas.core import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 122, in <module>
    from pandas.core.describe import describe_ndframe
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/describe.py", line 37, in <module>
    from pandas.core.reshape.concat import concat
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/reshape/concat.py", line 45, in <module>
    from pandas.core.internals import concatenate_managers
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/internals/__init__.py", line 17, in <module>
    from pandas.core.internals.concat import concatenate_managers
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/internals/concat.py", line 58, in <module>
    from pandas.core.internals.managers import BlockManager
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py", line 79, in <module>
    from pandas.core.internals.ops import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 963, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 906, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1280, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1252, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1391, in find_spec
  File "<frozen importlib._bootstrap_external>", line 59, in _path_join
  File "<frozen importlib._bootstrap_external>", line 59, in <listcomp>
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 9211
[2023-03-28 22:33:49,171] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:33:49,421] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 31.339 seconds
[2023-03-28 22:34:20,869] {processor.py:163} INFO - Started process (PID=9273) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:34:20,906] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:34:20,923] {logging_mixin.py:109} INFO - [2023-03-28 22:34:20,922] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:34:54,975] {logging_mixin.py:109} INFO - [2023-03-28 22:34:51,693] {timeout.py:36} ERROR - Process timed out, PID: 9273
[2023-03-28 22:34:55,033] {logging_mixin.py:109} INFO - [2023-03-28 22:34:55,002] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp1pfve9i3/tmpxg4a707h'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 17, in <module>
    import os
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 9273
[2023-03-28 22:34:56,197] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:34:57,069] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 36.293 seconds
[2023-03-28 22:35:06,662] {processor.py:163} INFO - Started process (PID=9353) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:35:06,734] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:35:06,775] {logging_mixin.py:109} INFO - [2023-03-28 22:35:06,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:35:37,005] {logging_mixin.py:109} INFO - [2023-03-28 22:35:36,959] {timeout.py:36} ERROR - Process timed out, PID: 9353
[2023-03-28 22:35:37,400] {logging_mixin.py:109} INFO - [2023-03-28 22:35:37,063] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 4, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 143, in <module>
    from pandas.io.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/api.py", line 24, in <module>
    from pandas.io.pickle import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 963, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 906, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1280, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1252, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1392, in find_spec
  File "<frozen importlib._bootstrap>", line 224, in _verbose_message
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 496, in _exit_gracefully
    self.log.debug("Current Stacktrace is: %s", '\n'.join(map(str, inspect.stack())))
  File "/usr/local/lib/python3.7/inspect.py", line 1513, in stack
    return getouterframes(sys._getframe(1), context)
  File "/usr/local/lib/python3.7/inspect.py", line 1490, in getouterframes
    frameinfo = (frame,) + getframeinfo(frame, context)
  File "/usr/local/lib/python3.7/inspect.py", line 1464, in getframeinfo
    lines, lnum = findsource(frame)
  File "/usr/local/lib/python3.7/inspect.py", line 780, in findsource
    module = getmodule(object, file)
  File "/usr/local/lib/python3.7/inspect.py", line 742, in getmodule
    os.path.realpath(f)] = module.__name__
  File "/usr/local/lib/python3.7/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/usr/local/lib/python3.7/posixpath.py", line 429, in _joinrealpath
    if not islink(newpath):
  File "/usr/local/lib/python3.7/posixpath.py", line 171, in islink
    st = os.lstat(path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 9353
[2023-03-28 22:35:38,264] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:35:38,857] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 32.394 seconds
[2023-03-28 22:39:24,531] {processor.py:163} INFO - Started process (PID=167) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:39:24,544] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:39:24,556] {logging_mixin.py:109} INFO - [2023-03-28 22:39:24,556] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:39:54,578] {logging_mixin.py:109} INFO - [2023-03-28 22:39:54,577] {timeout.py:36} ERROR - Process timed out, PID: 167
[2023-03-28 22:39:54,604] {logging_mixin.py:109} INFO - [2023-03-28 22:39:54,584] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 167
[2023-03-28 22:39:54,834] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:39:54,971] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.452 seconds
[2023-03-28 22:40:25,662] {processor.py:163} INFO - Started process (PID=284) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:40:25,676] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:40:25,681] {logging_mixin.py:109} INFO - [2023-03-28 22:40:25,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:40:55,691] {logging_mixin.py:109} INFO - [2023-03-28 22:40:55,689] {timeout.py:36} ERROR - Process timed out, PID: 284
[2023-03-28 22:40:55,701] {logging_mixin.py:109} INFO - [2023-03-28 22:40:55,694] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 284
[2023-03-28 22:40:55,705] {logging_mixin.py:109} INFO - [2023-03-28 22:40:55,704] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:40:55,717] {logging_mixin.py:109} INFO - [2023-03-28 22:40:55,707] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 284

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:40:55,729] {logging_mixin.py:109} INFO - [2023-03-28 22:40:55,722] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:40:55,840] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:40:55,921] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.267 seconds
[2023-03-28 22:41:26,380] {processor.py:163} INFO - Started process (PID=423) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:41:26,385] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:41:26,388] {logging_mixin.py:109} INFO - [2023-03-28 22:41:26,387] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:41:56,400] {logging_mixin.py:109} INFO - [2023-03-28 22:41:56,398] {timeout.py:36} ERROR - Process timed out, PID: 423
[2023-03-28 22:41:56,411] {logging_mixin.py:109} INFO - [2023-03-28 22:41:56,405] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 423
[2023-03-28 22:41:56,415] {logging_mixin.py:109} INFO - [2023-03-28 22:41:56,414] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:41:56,432] {logging_mixin.py:109} INFO - [2023-03-28 22:41:56,418] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 423

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:41:56,444] {logging_mixin.py:109} INFO - [2023-03-28 22:41:56,439] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:41:56,538] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:41:56,671] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.301 seconds
[2023-03-28 22:42:27,502] {processor.py:163} INFO - Started process (PID=592) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:42:27,505] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:42:27,510] {logging_mixin.py:109} INFO - [2023-03-28 22:42:27,509] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:42:57,523] {logging_mixin.py:109} INFO - [2023-03-28 22:42:57,521] {timeout.py:36} ERROR - Process timed out, PID: 592
[2023-03-28 22:42:57,549] {logging_mixin.py:109} INFO - [2023-03-28 22:42:57,544] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 592
[2023-03-28 22:42:57,553] {logging_mixin.py:109} INFO - [2023-03-28 22:42:57,552] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:42:57,567] {logging_mixin.py:109} INFO - [2023-03-28 22:42:57,555] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 592

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:42:57,579] {logging_mixin.py:109} INFO - [2023-03-28 22:42:57,577] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:42:57,673] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:42:57,745] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.249 seconds
[2023-03-28 22:43:28,183] {processor.py:163} INFO - Started process (PID=769) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:43:28,187] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:43:28,190] {logging_mixin.py:109} INFO - [2023-03-28 22:43:28,189] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:43:58,201] {logging_mixin.py:109} INFO - [2023-03-28 22:43:58,199] {timeout.py:36} ERROR - Process timed out, PID: 769
[2023-03-28 22:43:58,213] {logging_mixin.py:109} INFO - [2023-03-28 22:43:58,203] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 769
[2023-03-28 22:43:58,218] {logging_mixin.py:109} INFO - [2023-03-28 22:43:58,215] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:43:58,225] {logging_mixin.py:109} INFO - [2023-03-28 22:43:58,220] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 769

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:43:58,250] {logging_mixin.py:109} INFO - [2023-03-28 22:43:58,242] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:43:58,369] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:43:58,423] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.247 seconds
[2023-03-28 22:44:01,570] {processor.py:163} INFO - Started process (PID=933) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:44:01,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:44:01,578] {logging_mixin.py:109} INFO - [2023-03-28 22:44:01,578] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:44:31,591] {logging_mixin.py:109} INFO - [2023-03-28 22:44:31,589] {timeout.py:36} ERROR - Process timed out, PID: 933
[2023-03-28 22:44:31,599] {logging_mixin.py:109} INFO - [2023-03-28 22:44:31,594] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 933
[2023-03-28 22:44:31,603] {logging_mixin.py:109} INFO - [2023-03-28 22:44:31,603] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:44:31,616] {logging_mixin.py:109} INFO - [2023-03-28 22:44:31,606] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 933

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:44:31,630] {logging_mixin.py:109} INFO - [2023-03-28 22:44:31,619] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 44, in <module>
    .config(conf=sc.getConf())
  File "/opt/spark/python/pyspark/sql/session.py", line 233, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/opt/spark/python/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o106.sessionState
[2023-03-28 22:44:31,672] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:44:31,717] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.154 seconds
[2023-03-28 22:45:02,032] {processor.py:163} INFO - Started process (PID=1109) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:45:02,036] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:45:02,039] {logging_mixin.py:109} INFO - [2023-03-28 22:45:02,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:45:32,050] {logging_mixin.py:109} INFO - [2023-03-28 22:45:32,048] {timeout.py:36} ERROR - Process timed out, PID: 1109
[2023-03-28 22:45:32,059] {logging_mixin.py:109} INFO - [2023-03-28 22:45:32,053] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1109
[2023-03-28 22:45:32,065] {logging_mixin.py:109} INFO - [2023-03-28 22:45:32,065] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:45:32,089] {logging_mixin.py:109} INFO - [2023-03-28 22:45:32,067] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1109

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:45:32,127] {logging_mixin.py:109} INFO - [2023-03-28 22:45:32,099] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 44, in <module>
    .config(conf=sc.getConf())
  File "/opt/spark/python/pyspark/sql/session.py", line 231, in getOrCreate
    session = SparkSession(sc)
  File "/opt/spark/python/pyspark/sql/session.py", line 253, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc())
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession
[2023-03-28 22:45:32,208] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:45:32,276] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.252 seconds
[2023-03-28 22:46:02,466] {processor.py:163} INFO - Started process (PID=1300) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:46:02,470] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:46:02,473] {logging_mixin.py:109} INFO - [2023-03-28 22:46:02,473] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:46:32,482] {logging_mixin.py:109} INFO - [2023-03-28 22:46:32,480] {timeout.py:36} ERROR - Process timed out, PID: 1300
[2023-03-28 22:46:32,492] {logging_mixin.py:109} INFO - [2023-03-28 22:46:32,486] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1300
[2023-03-28 22:46:32,494] {logging_mixin.py:109} INFO - [2023-03-28 22:46:32,494] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:46:32,508] {logging_mixin.py:109} INFO - [2023-03-28 22:46:32,496] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1300

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:46:32,528] {logging_mixin.py:109} INFO - [2023-03-28 22:46:32,516] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 44, in <module>
    .config(conf=sc.getConf())
  File "/opt/spark/python/pyspark/sql/session.py", line 231, in getOrCreate
    session = SparkSession(sc)
  File "/opt/spark/python/pyspark/sql/session.py", line 253, in __init__
    jsparkSession = self._jvm.SparkSession(self._jsc.sc())
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.sql.SparkSession
[2023-03-28 22:46:32,617] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:46:32,709] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.250 seconds
[2023-03-28 22:47:03,130] {processor.py:163} INFO - Started process (PID=1493) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:47:03,134] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:47:03,136] {logging_mixin.py:109} INFO - [2023-03-28 22:47:03,136] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:47:33,148] {logging_mixin.py:109} INFO - [2023-03-28 22:47:33,146] {timeout.py:36} ERROR - Process timed out, PID: 1493
[2023-03-28 22:47:33,171] {logging_mixin.py:109} INFO - [2023-03-28 22:47:33,157] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1493
[2023-03-28 22:47:33,239] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:47:33,297] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.173 seconds
[2023-03-28 22:48:03,739] {processor.py:163} INFO - Started process (PID=1586) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:48:03,742] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:48:03,744] {logging_mixin.py:109} INFO - [2023-03-28 22:48:03,744] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:48:33,753] {logging_mixin.py:109} INFO - [2023-03-28 22:48:33,752] {timeout.py:36} ERROR - Process timed out, PID: 1586
[2023-03-28 22:48:33,766] {logging_mixin.py:109} INFO - [2023-03-28 22:48:33,756] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1586
[2023-03-28 22:48:33,772] {logging_mixin.py:109} INFO - [2023-03-28 22:48:33,771] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:48:33,801] {logging_mixin.py:109} INFO - [2023-03-28 22:48:33,778] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1586

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:48:33,809] {logging_mixin.py:109} INFO - [2023-03-28 22:48:33,807] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:48:33,895] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:48:33,955] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.222 seconds
[2023-03-28 22:49:04,265] {processor.py:163} INFO - Started process (PID=1754) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:49:04,269] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:49:04,271] {logging_mixin.py:109} INFO - [2023-03-28 22:49:04,271] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:49:34,283] {logging_mixin.py:109} INFO - [2023-03-28 22:49:34,281] {timeout.py:36} ERROR - Process timed out, PID: 1754
[2023-03-28 22:49:34,292] {logging_mixin.py:109} INFO - [2023-03-28 22:49:34,286] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1754
[2023-03-28 22:49:34,295] {logging_mixin.py:109} INFO - [2023-03-28 22:49:34,295] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:49:34,306] {logging_mixin.py:109} INFO - [2023-03-28 22:49:34,297] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1754

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:49:34,318] {logging_mixin.py:109} INFO - [2023-03-28 22:49:34,313] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:49:34,412] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:49:34,523] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.265 seconds
[2023-03-28 22:49:50,564] {processor.py:163} INFO - Started process (PID=1905) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:49:50,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:49:50,577] {logging_mixin.py:109} INFO - [2023-03-28 22:49:50,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:50:20,592] {logging_mixin.py:109} INFO - [2023-03-28 22:50:20,590] {timeout.py:36} ERROR - Process timed out, PID: 1905
[2023-03-28 22:50:20,602] {logging_mixin.py:109} INFO - [2023-03-28 22:50:20,594] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1905
[2023-03-28 22:50:20,605] {logging_mixin.py:109} INFO - [2023-03-28 22:50:20,604] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:50:20,615] {logging_mixin.py:109} INFO - [2023-03-28 22:50:20,609] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1905

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:50:20,632] {logging_mixin.py:109} INFO - [2023-03-28 22:50:20,629] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:50:20,769] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:50:20,796] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.240 seconds
[2023-03-28 22:50:51,209] {processor.py:163} INFO - Started process (PID=2053) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:50:51,217] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:50:51,222] {logging_mixin.py:109} INFO - [2023-03-28 22:50:51,222] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:51:21,236] {logging_mixin.py:109} INFO - [2023-03-28 22:51:21,234] {timeout.py:36} ERROR - Process timed out, PID: 2053
[2023-03-28 22:51:21,244] {logging_mixin.py:109} INFO - [2023-03-28 22:51:21,238] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2053
[2023-03-28 22:51:21,247] {logging_mixin.py:109} INFO - [2023-03-28 22:51:21,246] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:51:21,259] {logging_mixin.py:109} INFO - [2023-03-28 22:51:21,250] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2053

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:51:21,267] {logging_mixin.py:109} INFO - [2023-03-28 22:51:21,262] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:51:21,335] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:51:21,396] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.195 seconds
[2023-03-28 22:51:51,663] {processor.py:163} INFO - Started process (PID=2194) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:51:51,668] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:51:51,671] {logging_mixin.py:109} INFO - [2023-03-28 22:51:51,670] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:52:21,682] {logging_mixin.py:109} INFO - [2023-03-28 22:52:21,680] {timeout.py:36} ERROR - Process timed out, PID: 2194
[2023-03-28 22:52:21,690] {logging_mixin.py:109} INFO - [2023-03-28 22:52:21,685] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2194
[2023-03-28 22:52:21,693] {logging_mixin.py:109} INFO - [2023-03-28 22:52:21,692] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:52:21,704] {logging_mixin.py:109} INFO - [2023-03-28 22:52:21,695] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2194

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:52:21,717] {logging_mixin.py:109} INFO - [2023-03-28 22:52:21,708] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:52:21,777] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:52:21,853] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.197 seconds
[2023-03-28 22:52:24,793] {processor.py:163} INFO - Started process (PID=2301) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:52:24,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:52:24,801] {logging_mixin.py:109} INFO - [2023-03-28 22:52:24,800] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:52:54,816] {logging_mixin.py:109} INFO - [2023-03-28 22:52:54,814] {timeout.py:36} ERROR - Process timed out, PID: 2301
[2023-03-28 22:52:54,829] {logging_mixin.py:109} INFO - [2023-03-28 22:52:54,821] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2301
[2023-03-28 22:52:54,909] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:52:54,967] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.183 seconds
[2023-03-28 22:53:25,533] {processor.py:163} INFO - Started process (PID=2380) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:53:25,539] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:53:25,542] {logging_mixin.py:109} INFO - [2023-03-28 22:53:25,542] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:53:55,554] {logging_mixin.py:109} INFO - [2023-03-28 22:53:55,552] {timeout.py:36} ERROR - Process timed out, PID: 2380
[2023-03-28 22:53:55,562] {logging_mixin.py:109} INFO - [2023-03-28 22:53:55,557] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2380
[2023-03-28 22:53:55,565] {logging_mixin.py:109} INFO - [2023-03-28 22:53:55,565] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 22:53:55,582] {logging_mixin.py:109} INFO - [2023-03-28 22:53:55,568] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 2380

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 22:53:55,605] {logging_mixin.py:109} INFO - [2023-03-28 22:53:55,595] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 22:53:55,725] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 22:53:55,770] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.245 seconds
[2023-03-28 22:54:26,299] {processor.py:163} INFO - Started process (PID=2507) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:54:26,303] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:54:26,306] {logging_mixin.py:109} INFO - [2023-03-28 22:54:26,305] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 22:59:46,624] {processor.py:163} INFO - Started process (PID=216) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 22:59:46,645] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 22:59:46,657] {logging_mixin.py:109} INFO - [2023-03-28 22:59:46,656] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:00:16,694] {logging_mixin.py:109} INFO - [2023-03-28 23:00:16,692] {timeout.py:36} ERROR - Process timed out, PID: 216
[2023-03-28 23:00:16,712] {logging_mixin.py:109} INFO - [2023-03-28 23:00:16,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 216
[2023-03-28 23:00:16,849] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:00:16,975] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.373 seconds
[2023-03-28 23:00:47,315] {processor.py:163} INFO - Started process (PID=333) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:00:47,324] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:00:47,333] {logging_mixin.py:109} INFO - [2023-03-28 23:00:47,332] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:01:17,351] {logging_mixin.py:109} INFO - [2023-03-28 23:01:17,348] {timeout.py:36} ERROR - Process timed out, PID: 333
[2023-03-28 23:01:17,361] {logging_mixin.py:109} INFO - [2023-03-28 23:01:17,355] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 333
[2023-03-28 23:01:17,364] {logging_mixin.py:109} INFO - [2023-03-28 23:01:17,363] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 23:01:17,387] {logging_mixin.py:109} INFO - [2023-03-28 23:01:17,366] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 333

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 23:01:17,408] {logging_mixin.py:109} INFO - [2023-03-28 23:01:17,401] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 23:01:17,487] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:01:17,544] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.257 seconds
[2023-03-28 23:01:47,852] {processor.py:163} INFO - Started process (PID=476) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:01:47,858] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:01:47,864] {logging_mixin.py:109} INFO - [2023-03-28 23:01:47,863] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:02:17,893] {logging_mixin.py:109} INFO - [2023-03-28 23:02:17,891] {timeout.py:36} ERROR - Process timed out, PID: 476
[2023-03-28 23:02:17,900] {logging_mixin.py:109} INFO - [2023-03-28 23:02:17,896] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 476
[2023-03-28 23:02:17,902] {logging_mixin.py:109} INFO - [2023-03-28 23:02:17,902] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 23:02:17,910] {logging_mixin.py:109} INFO - [2023-03-28 23:02:17,904] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 476

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 23:02:17,914] {logging_mixin.py:109} INFO - [2023-03-28 23:02:17,911] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 23:02:17,954] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:02:18,005] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.164 seconds
[2023-03-28 23:02:48,396] {processor.py:163} INFO - Started process (PID=652) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:02:48,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:02:48,410] {logging_mixin.py:109} INFO - [2023-03-28 23:02:48,409] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:03:18,426] {logging_mixin.py:109} INFO - [2023-03-28 23:03:18,424] {timeout.py:36} ERROR - Process timed out, PID: 652
[2023-03-28 23:03:18,436] {logging_mixin.py:109} INFO - [2023-03-28 23:03:18,429] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 652
[2023-03-28 23:03:18,440] {logging_mixin.py:109} INFO - [2023-03-28 23:03:18,439] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 23:03:18,455] {logging_mixin.py:109} INFO - [2023-03-28 23:03:18,442] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 652

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 23:03:18,465] {logging_mixin.py:109} INFO - [2023-03-28 23:03:18,459] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 23:03:18,501] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:03:18,528] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.146 seconds
[2023-03-28 23:03:48,747] {processor.py:163} INFO - Started process (PID=822) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:03:48,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:03:48,755] {logging_mixin.py:109} INFO - [2023-03-28 23:03:48,755] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:04:18,766] {logging_mixin.py:109} INFO - [2023-03-28 23:04:18,764] {timeout.py:36} ERROR - Process timed out, PID: 822
[2023-03-28 23:04:39,678] {processor.py:163} INFO - Started process (PID=994) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:04:39,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:04:39,685] {logging_mixin.py:109} INFO - [2023-03-28 23:04:39,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:05:09,696] {logging_mixin.py:109} INFO - [2023-03-28 23:05:09,694] {timeout.py:36} ERROR - Process timed out, PID: 994
[2023-03-28 23:05:09,706] {logging_mixin.py:109} INFO - [2023-03-28 23:05:09,700] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 994
[2023-03-28 23:05:09,711] {logging_mixin.py:109} INFO - [2023-03-28 23:05:09,710] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 23:05:09,729] {logging_mixin.py:109} INFO - [2023-03-28 23:05:09,713] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 994

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 23:05:09,751] {logging_mixin.py:109} INFO - [2023-03-28 23:05:09,734] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 23:05:09,861] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:05:09,923] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.252 seconds
[2023-03-28 23:05:40,460] {processor.py:163} INFO - Started process (PID=1165) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:05:40,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:05:40,467] {logging_mixin.py:109} INFO - [2023-03-28 23:05:40,467] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:06:10,480] {logging_mixin.py:109} INFO - [2023-03-28 23:06:10,477] {timeout.py:36} ERROR - Process timed out, PID: 1165
[2023-03-28 23:06:10,492] {logging_mixin.py:109} INFO - [2023-03-28 23:06:10,485] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1165
[2023-03-28 23:06:10,494] {logging_mixin.py:109} INFO - [2023-03-28 23:06:10,494] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 23:06:10,503] {logging_mixin.py:109} INFO - [2023-03-28 23:06:10,496] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 1165

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 23:06:10,517] {logging_mixin.py:109} INFO - [2023-03-28 23:06:10,515] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 23:06:10,609] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:06:10,675] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.220 seconds
[2023-03-28 23:06:41,191] {processor.py:163} INFO - Started process (PID=1339) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:06:41,195] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:06:41,199] {logging_mixin.py:109} INFO - [2023-03-28 23:06:41,198] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:27:01,281] {processor.py:163} INFO - Started process (PID=221) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:27:01,287] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:27:01,295] {logging_mixin.py:109} INFO - [2023-03-28 23:27:01,295] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:27:31,312] {logging_mixin.py:109} INFO - [2023-03-28 23:27:31,310] {timeout.py:36} ERROR - Process timed out, PID: 221
[2023-03-28 23:27:31,326] {logging_mixin.py:109} INFO - [2023-03-28 23:27:31,319] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 15, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 221
[2023-03-28 23:27:31,536] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:27:31,708] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.433 seconds
[2023-03-28 23:35:34,140] {processor.py:163} INFO - Started process (PID=249) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:35:34,163] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:35:34,174] {logging_mixin.py:109} INFO - [2023-03-28 23:35:34,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:36:04,202] {logging_mixin.py:109} INFO - [2023-03-28 23:36:04,200] {timeout.py:36} ERROR - Process timed out, PID: 249
[2023-03-28 23:36:04,218] {logging_mixin.py:109} INFO - [2023-03-28 23:36:04,210] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 14, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 249
[2023-03-28 23:36:04,353] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:36:04,453] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.338 seconds
[2023-03-28 23:36:35,144] {processor.py:163} INFO - Started process (PID=362) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:36:35,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:36:35,162] {logging_mixin.py:109} INFO - [2023-03-28 23:36:35,162] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:37:05,197] {logging_mixin.py:109} INFO - [2023-03-28 23:37:05,194] {timeout.py:36} ERROR - Process timed out, PID: 362
[2023-03-28 23:37:05,208] {logging_mixin.py:109} INFO - [2023-03-28 23:37:05,201] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 362
[2023-03-28 23:37:05,210] {logging_mixin.py:109} INFO - [2023-03-28 23:37:05,210] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 23:37:05,220] {logging_mixin.py:109} INFO - [2023-03-28 23:37:05,213] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 362

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 23:37:05,226] {logging_mixin.py:109} INFO - [2023-03-28 23:37:05,224] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 14, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 23:37:05,269] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:37:05,302] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.169 seconds
[2023-03-28 23:37:35,578] {processor.py:163} INFO - Started process (PID=504) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:37:35,585] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:37:35,590] {logging_mixin.py:109} INFO - [2023-03-28 23:37:35,589] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:44:57,874] {processor.py:163} INFO - Started process (PID=220) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:44:57,890] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:44:57,899] {logging_mixin.py:109} INFO - [2023-03-28 23:44:57,899] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:45:27,938] {logging_mixin.py:109} INFO - [2023-03-28 23:45:27,936] {timeout.py:36} ERROR - Process timed out, PID: 220
[2023-03-28 23:45:27,966] {logging_mixin.py:109} INFO - [2023-03-28 23:45:27,948] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 14, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 220
[2023-03-28 23:45:28,101] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:45:28,219] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.367 seconds
[2023-03-28 23:45:58,819] {processor.py:163} INFO - Started process (PID=335) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:45:58,849] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:45:58,876] {logging_mixin.py:109} INFO - [2023-03-28 23:45:58,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:46:28,898] {logging_mixin.py:109} INFO - [2023-03-28 23:46:28,895] {timeout.py:36} ERROR - Process timed out, PID: 335
[2023-03-28 23:46:28,914] {logging_mixin.py:109} INFO - [2023-03-28 23:46:28,904] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 14, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/spark/python/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 335
[2023-03-28 23:46:29,018] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:46:29,063] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.291 seconds
[2023-03-28 23:46:59,377] {processor.py:163} INFO - Started process (PID=455) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:46:59,404] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:46:59,414] {logging_mixin.py:109} INFO - [2023-03-28 23:46:59,413] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:47:29,432] {logging_mixin.py:109} INFO - [2023-03-28 23:47:29,429] {timeout.py:36} ERROR - Process timed out, PID: 455
[2023-03-28 23:47:29,441] {logging_mixin.py:109} INFO - [2023-03-28 23:47:29,435] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 455
[2023-03-28 23:47:29,443] {logging_mixin.py:109} INFO - [2023-03-28 23:47:29,443] {clientserver.py:507} INFO - Closing down clientserver connection
[2023-03-28 23:47:29,450] {logging_mixin.py:109} INFO - [2023-03-28 23:47:29,445] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/first_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.3/best-practices.html#reducing-dag-complexity, PID: 455

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py", line 504, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-03-28 23:47:29,455] {logging_mixin.py:109} INFO - [2023-03-28 23:47:29,453] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 14, in <module>
    from stock_data_transform import transform_stock_data
  File "/opt/airflow/dags/stock_data_transform.py", line 27, in <module>
    sc = SparkContext(conf=conf)
  File "/opt/spark/python/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/opt/spark/python/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/spark/python/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/opt/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-03-28 23:47:29,500] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:47:29,526] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 30.189 seconds
[2023-03-28 23:47:59,843] {processor.py:163} INFO - Started process (PID=631) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:47:59,854] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:47:59,860] {logging_mixin.py:109} INFO - [2023-03-28 23:47:59,859] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:06,308] {logging_mixin.py:109} INFO - [2023-03-28 23:48:06,303] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 21, in <module>
    from etl_operation_functions import (
ImportError: cannot import name 'ingest_from_gcs_to_bquery' from 'etl_operation_functions' (/opt/airflow/dags/etl_operation_functions.py)
[2023-03-28 23:48:06,340] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:06,370] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 6.544 seconds
[2023-03-28 23:48:36,604] {processor.py:163} INFO - Started process (PID=669) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:36,610] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:48:36,613] {logging_mixin.py:109} INFO - [2023-03-28 23:48:36,612] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:41,185] {logging_mixin.py:109} INFO - [2023-03-28 23:48:41,179] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 21, in <module>
    from etl_operation_functions import (
ImportError: cannot import name 'ingest_from_gcs_to_bquery' from 'etl_operation_functions' (/opt/airflow/dags/etl_operation_functions.py)
[2023-03-28 23:48:41,214] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:41,240] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.643 seconds
[2023-03-28 23:48:46,346] {processor.py:163} INFO - Started process (PID=675) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:46,350] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:48:46,353] {logging_mixin.py:109} INFO - [2023-03-28 23:48:46,353] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:50,114] {logging_mixin.py:109} INFO - [2023-03-28 23:48:50,109] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 19, in <module>
    from etl_operation_functions import (
ImportError: cannot import name 'ingest_from_gcs_to_bquery' from 'etl_operation_functions' (/opt/airflow/dags/etl_operation_functions.py)
[2023-03-28 23:48:50,139] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:50,159] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 3.820 seconds
[2023-03-28 23:48:56,254] {processor.py:163} INFO - Started process (PID=697) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:48:56,260] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:48:56,266] {logging_mixin.py:109} INFO - [2023-03-28 23:48:56,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:49:01,172] {logging_mixin.py:109} INFO - [2023-03-28 23:49:01,160] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:49:01,202] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:49:01,226] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.980 seconds
[2023-03-28 23:49:31,451] {processor.py:163} INFO - Started process (PID=719) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:49:31,458] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:49:31,462] {logging_mixin.py:109} INFO - [2023-03-28 23:49:31,461] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:49:35,069] {logging_mixin.py:109} INFO - [2023-03-28 23:49:35,058] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:49:35,100] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:49:35,127] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 3.684 seconds
[2023-03-28 23:50:05,310] {processor.py:163} INFO - Started process (PID=757) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:50:05,314] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:50:05,317] {logging_mixin.py:109} INFO - [2023-03-28 23:50:05,317] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:50:08,760] {logging_mixin.py:109} INFO - [2023-03-28 23:50:08,752] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:50:08,786] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:50:08,805] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 3.502 seconds
[2023-03-28 23:50:39,071] {processor.py:163} INFO - Started process (PID=795) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:50:39,082] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:50:39,087] {logging_mixin.py:109} INFO - [2023-03-28 23:50:39,087] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:50:43,543] {logging_mixin.py:109} INFO - [2023-03-28 23:50:43,532] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:50:43,575] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:50:43,604] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.540 seconds
[2023-03-28 23:51:14,035] {processor.py:163} INFO - Started process (PID=816) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:51:14,044] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:51:14,047] {logging_mixin.py:109} INFO - [2023-03-28 23:51:14,047] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:51:18,545] {logging_mixin.py:109} INFO - [2023-03-28 23:51:18,534] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:51:18,578] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:51:18,603] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.575 seconds
[2023-03-28 23:51:48,821] {processor.py:163} INFO - Started process (PID=854) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:51:48,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:51:48,831] {logging_mixin.py:109} INFO - [2023-03-28 23:51:48,829] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:51:51,978] {logging_mixin.py:109} INFO - [2023-03-28 23:51:51,969] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:51:52,003] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:51:52,023] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 3.214 seconds
[2023-03-28 23:52:22,145] {processor.py:163} INFO - Started process (PID=892) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:52:22,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:52:22,155] {logging_mixin.py:109} INFO - [2023-03-28 23:52:22,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:52:26,277] {logging_mixin.py:109} INFO - [2023-03-28 23:52:26,267] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:52:26,304] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:52:26,327] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.190 seconds
[2023-03-28 23:52:56,514] {processor.py:163} INFO - Started process (PID=930) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:52:56,519] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:52:56,523] {logging_mixin.py:109} INFO - [2023-03-28 23:52:56,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:53:00,798] {logging_mixin.py:109} INFO - [2023-03-28 23:53:00,787] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:53:00,835] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:53:00,860] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.354 seconds
[2023-03-28 23:53:31,096] {processor.py:163} INFO - Started process (PID=952) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:53:31,099] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:53:31,102] {logging_mixin.py:109} INFO - [2023-03-28 23:53:31,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:53:34,424] {logging_mixin.py:109} INFO - [2023-03-28 23:53:34,414] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:53:34,456] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:53:34,482] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 3.392 seconds
[2023-03-28 23:54:04,693] {processor.py:163} INFO - Started process (PID=991) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:54:04,699] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:54:04,702] {logging_mixin.py:109} INFO - [2023-03-28 23:54:04,702] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:54:08,272] {logging_mixin.py:109} INFO - [2023-03-28 23:54:08,261] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:54:08,308] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:54:08,330] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 3.644 seconds
[2023-03-28 23:54:38,579] {processor.py:163} INFO - Started process (PID=1029) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:54:38,584] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:54:38,588] {logging_mixin.py:109} INFO - [2023-03-28 23:54:38,588] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:54:43,109] {logging_mixin.py:109} INFO - [2023-03-28 23:54:43,100] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:54:43,139] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:54:43,172] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.600 seconds
[2023-03-28 23:55:13,427] {processor.py:163} INFO - Started process (PID=1051) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:55:13,432] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:55:13,435] {logging_mixin.py:109} INFO - [2023-03-28 23:55:13,434] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:55:17,825] {logging_mixin.py:109} INFO - [2023-03-28 23:55:17,815] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:55:17,857] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:55:17,882] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.461 seconds
[2023-03-28 23:55:48,069] {processor.py:163} INFO - Started process (PID=1089) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:55:48,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:55:48,077] {logging_mixin.py:109} INFO - [2023-03-28 23:55:48,076] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:55:51,270] {logging_mixin.py:109} INFO - [2023-03-28 23:55:51,262] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 87, in <module>
    "destination_blob_path": f"{destination_blob_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (ingest to gcs) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-03-28 23:55:51,297] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:55:51,315] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 3.255 seconds
[2023-03-28 23:56:17,391] {processor.py:163} INFO - Started process (PID=1126) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:56:17,397] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:56:17,400] {logging_mixin.py:109} INFO - [2023-03-28 23:56:17,400] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:56:23,261] {logging_mixin.py:109} INFO - [2023-03-28 23:56:23,246] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 93, in <module>
    "output_data_path": f"{gcs_output_data_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 553, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 175, in add
    raise DuplicateTaskIdFound(f"Task id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'process_data_task' has already been added to the DAG
[2023-03-28 23:56:23,321] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:56:23,349] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 5.966 seconds
[2023-03-28 23:56:53,622] {processor.py:163} INFO - Started process (PID=1148) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:56:53,628] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:56:53,631] {logging_mixin.py:109} INFO - [2023-03-28 23:56:53,630] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:56:58,088] {logging_mixin.py:109} INFO - [2023-03-28 23:56:58,077] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/first_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/first_dag.py", line 93, in <module>
    "output_data_path": f"{gcs_output_data_path}",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 553, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 175, in add
    raise DuplicateTaskIdFound(f"Task id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'process_data_task' has already been added to the DAG
[2023-03-28 23:56:58,118] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:56:58,159] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.545 seconds
[2023-03-28 23:56:59,979] {processor.py:163} INFO - Started process (PID=1170) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:56:59,983] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:56:59,986] {logging_mixin.py:109} INFO - [2023-03-28 23:56:59,986] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:57:04,768] {processor.py:654} INFO - DAG(s) dict_keys(['SP_500_DATA_PIPELINE_v2']) retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:57:21,544] {logging_mixin.py:109} INFO - [2023-03-28 23:57:21,544] {manager.py:496} INFO - Created Permission View: can read on DAG:SP_500_DATA_PIPELINE_v2
[2023-03-28 23:57:21,572] {logging_mixin.py:109} INFO - [2023-03-28 23:57:21,571] {manager.py:496} INFO - Created Permission View: can edit on DAG:SP_500_DATA_PIPELINE_v2
[2023-03-28 23:57:21,577] {logging_mixin.py:109} INFO - [2023-03-28 23:57:21,575] {dag.py:2396} INFO - Sync 1 DAGs
[2023-03-28 23:57:21,611] {logging_mixin.py:109} INFO - [2023-03-28 23:57:21,606] {dag.py:2415} INFO - Creating ORM DAG for SP_500_DATA_PIPELINE_v2
[2023-03-28 23:57:21,654] {logging_mixin.py:109} INFO - [2023-03-28 23:57:21,654] {dag.py:2935} INFO - Setting next_dagrun for SP_500_DATA_PIPELINE_v2 to 2023-03-28T23:57:04.676275+00:00
[2023-03-28 23:57:21,936] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 21.964 seconds
[2023-03-28 23:57:52,277] {processor.py:163} INFO - Started process (PID=1208) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:57:52,284] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:57:52,287] {logging_mixin.py:109} INFO - [2023-03-28 23:57:52,287] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:57:57,188] {processor.py:654} INFO - DAG(s) dict_keys(['SP_500_DATA_PIPELINE_v2']) retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:57:58,757] {logging_mixin.py:109} INFO - [2023-03-28 23:57:58,756] {dag.py:2396} INFO - Sync 1 DAGs
[2023-03-28 23:57:58,913] {logging_mixin.py:109} INFO - [2023-03-28 23:57:58,913] {dag.py:2935} INFO - Setting next_dagrun for SP_500_DATA_PIPELINE_v2 to 2023-03-28T23:57:57.130645+00:00
[2023-03-28 23:57:58,992] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 6.726 seconds
[2023-03-28 23:58:29,124] {processor.py:163} INFO - Started process (PID=1246) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:58:29,129] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:58:29,133] {logging_mixin.py:109} INFO - [2023-03-28 23:58:29,132] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:58:32,423] {processor.py:654} INFO - DAG(s) dict_keys(['SP_500_DATA_PIPELINE_v2']) retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:58:33,209] {logging_mixin.py:109} INFO - [2023-03-28 23:58:33,207] {dag.py:2396} INFO - Sync 1 DAGs
[2023-03-28 23:58:33,266] {logging_mixin.py:109} INFO - [2023-03-28 23:58:33,265] {dag.py:2935} INFO - Setting next_dagrun for SP_500_DATA_PIPELINE_v2 to 2023-03-28T23:58:32.380241+00:00
[2023-03-28 23:58:33,301] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 4.184 seconds
[2023-03-28 23:59:03,611] {processor.py:163} INFO - Started process (PID=1285) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:59:03,621] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:59:03,628] {logging_mixin.py:109} INFO - [2023-03-28 23:59:03,628] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:59:08,188] {processor.py:654} INFO - DAG(s) dict_keys(['SP_500_DATA_PIPELINE_v2']) retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:59:08,937] {logging_mixin.py:109} INFO - [2023-03-28 23:59:08,936] {dag.py:2396} INFO - Sync 1 DAGs
[2023-03-28 23:59:08,998] {logging_mixin.py:109} INFO - [2023-03-28 23:59:08,998] {dag.py:2935} INFO - Setting next_dagrun for SP_500_DATA_PIPELINE_v2 to 2023-03-28T23:59:08.144184+00:00
[2023-03-28 23:59:09,027] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 5.429 seconds
[2023-03-28 23:59:39,229] {processor.py:163} INFO - Started process (PID=1323) to work on /opt/airflow/dags/first_dag.py
[2023-03-28 23:59:39,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/first_dag.py for tasks to queue
[2023-03-28 23:59:39,239] {logging_mixin.py:109} INFO - [2023-03-28 23:59:39,238] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/first_dag.py
[2023-03-28 23:59:44,112] {processor.py:654} INFO - DAG(s) dict_keys(['SP_500_DATA_PIPELINE_v2']) retrieved from /opt/airflow/dags/first_dag.py
[2023-03-28 23:59:45,262] {logging_mixin.py:109} INFO - [2023-03-28 23:59:45,261] {dag.py:2396} INFO - Sync 1 DAGs
[2023-03-28 23:59:45,337] {logging_mixin.py:109} INFO - [2023-03-28 23:59:45,337] {dag.py:2935} INFO - Setting next_dagrun for SP_500_DATA_PIPELINE_v2 to 2023-03-28T23:59:44.055892+00:00
[2023-03-28 23:59:45,376] {processor.py:171} INFO - Processing /opt/airflow/dags/first_dag.py took 6.156 seconds
